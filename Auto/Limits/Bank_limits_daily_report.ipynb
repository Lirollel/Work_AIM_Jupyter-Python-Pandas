{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"Limits\" just started running\n"
     ]
    }
   ],
   "source": [
    "print('The \"Limits\" just started running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as ax\n",
    "import openpyxl\n",
    "from openpyxl.styles import Border, Side, PatternFill, Font, GradientFill, Alignment\n",
    "from openpyxl.drawing.image import Image\n",
    "import win32com.client as win32\n",
    "import os\n",
    "from PIL import ImageGrab\n",
    "import win32com.client\n",
    "\n",
    "olApp = win32.Dispatch('Outlook.Application')\n",
    "olNS = olApp.GetNameSpace('MAPI')\n",
    "\n",
    "import sys\n",
    "# sys.path.append(\"C:\\WorkFolder\\PythonScripts\")\n",
    "sys.path.append(\"C:\\\\Users\\\\KlimovaAnnaA\\\\Documents\\\\MyFiles\\\\Projects\\\\OCP\")\n",
    "from Defs import merge_SalesUnits\n",
    "from Defs import new_list\n",
    "from Defs import export_from_RISKCUSTOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual_sending = False # True/False Заполните это поле, если хотите отправить отчет даже после критичных уведомлений\n",
    "\n",
    "# Print_qualuty_check = True # Вынести QC в отдельный excel-файл? True/False\n",
    "# Display_QC_mail = True # Показать письмо QC для отправки? True/False\n",
    "# Send_QC_mail = True # Создать и отправить письмо для QC? True/False\n",
    "\n",
    "Print_to_excel = True # Создать excel-файл с расчетами? True/False\n",
    "Display_mail = True # Показать письмо для отправки? True/False\n",
    "Send_mail = False # Создать и отправить письмо с расчетами и графиком? True/False\n",
    "\n",
    "mail_to_Ech = 'TarakanovMIu@aimmngt.com;Aleksandr.A.Ovchinnikov@eurochem.ru;Anastasiya.Barmenkova@eurochem.ru;denis.perevezentsev@rowanfm.cn;Tatyana.Votyakova@eurochem.ru;Aleksandr.Ostreyko@eurochem.ru;IvashovaEA@rowanfm.com;Axana.Davletkireeva@eurochemgroup.ae; ZubkovNA@aimmngt.com; <Pavel.Burundukov@rowanfm.ae>; GerchakAI@aimmngt.com;TimokhinEV@aimmngt.com;Pavel.Lyubin@greenms.ae;KotinaOI@aimmngt.com' # Получатель письма\n",
    "mail_ECH_SAM ='<TarakanovMIu@aimmngt.com>; denis.perevezentsev@rowanfm.cn; <Aleksandr.Ostreyko@eurochem.ru>;<persio.ravena@eurochemsam.com;<helio.pimentel@eurochemsam.com>; <renato.costa@eurochemsam.com>; <joao.cruz@eurochemsam.com>; <lua.pereira@eurochemsam.com>;  TimokhinEV@aimmngt.com; Pavel.Lyubin@greenms.ae;'\n",
    "mail_ECH_NAM = '<TarakanovMIu@aimmngt.com>; denis.perevezentsev@rowanfm.cn; <Aleksandr.Ostreyko@eurochem.ru>;  Donal.Lambert@eurochem-na.com;<Denis.Bukin@eurochem-na.com>; TimokhinEV@aimmngt.com; Pavel.Lyubin@greenms.ae;'\n",
    "mail_ECH_Europe ='<TarakanovMIu@aimmngt.com>; denis.perevezentsev@rowanfm.cn; <Aleksandr.Ostreyko@eurochem.ru>; <Aleksandr.Vasilyev@eurochemgroup.com>; TimokhinEV@aimmngt.com; Pavel.Lyubin@greenms.ae;'\n",
    "\n",
    "mail_to_Suek = 'TarakanovMIu@aimmngt.com;Aleksandr.A.Ovchinnikov@eurochem.ru;Anastasiya.Barmenkova@eurochem.ru;denis.perevezentsev@rowanfm.cn;MaltsevaAA@rowanfm.com;ChernicherBA@suek.ru;IvashovaEA@rowanfm.com;ZubkovNA@aimmngt.com; <Pavel.Burundukov@rowanfm.ae>; ruslan.minikeev@black-sand-commodities.ae;TsuranAS@suek.ru;PanteleevaTaV@suek.ru;GerchakAI@aimmngt.com;TimokhinEV@aimmngt.com;Pavel.Lyubin@greenms.ae;KotinaOI@aimmngt.com' # Получатель письма\n",
    "mail_from = 'KlimovaAnnaA@aimmngt.com'\n",
    "# signature = \"\"\"Maksim Tarakanov <br><br>\n",
    "    # Whatsapp: +7 915 161 29 12<br>\n",
    "    # Financial risk management\"\"\"\n",
    "signature = \"Financial risk management\"\n",
    "# mail_from = 'TarakanovMIu@aimmngt.com' # mail from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<TarakanovMIu@aimmngt.com>; denis.perevezentsev@rowanfm.cn; <Aleksandr.Ostreyko@eurochem.ru>;<persio.ravena@eurochemsam.com;<helio.pimentel@eurochemsam.com>; <renato.costa@eurochemsam.com>; <joao.cruz@eurochemsam.com>; <lua.pereira@eurochemsam.com>;  TimokhinEV@aimmngt.com; Pavel.Lyubin@greenms.ae;',\n",
       " '<TarakanovMIu@aimmngt.com>; denis.perevezentsev@rowanfm.cn; <Aleksandr.Ostreyko@eurochem.ru>;  Donal.Lambert@eurochem-na.com;<Denis.Bukin@eurochem-na.com>; TimokhinEV@aimmngt.com; Pavel.Lyubin@greenms.ae;',\n",
       " '<TarakanovMIu@aimmngt.com>; denis.perevezentsev@rowanfm.cn; <Aleksandr.Ostreyko@eurochem.ru>; <Aleksandr.Vasilyev@eurochemgroup.com>; TimokhinEV@aimmngt.com; Pavel.Lyubin@greenms.ae;')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mail_ECH_SAM, mail_ECH_NAM, mail_ECH_Europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:98: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_13764\\1071633976.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[5.68291700e-02 7.29200000e-05 0.00000000e+00 ... 0.00000000e+00\n",
      " 0.00000000e+00 5.48031657e-03]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  BABD_data_work.loc[BABD_data_work.accountStatus.isin(accountStatus_list), 'balanceUsd_activmoney_market'] = BABD_data_work.loc[BABD_data_work.accountStatus.isin(accountStatus_list), 'balanceUsd_mln']\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:98: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_13764\\1071633976.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  BABD_data_limit_not_na['Usage_activmoney_market'] = (BABD_data_limit_not_na.balanceUsd_activmoney_market/BABD_data_limit_not_na.Limit)*100\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_13764\\1071633976.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  BABD_data_limit_not_na['Usage'] = (BABD_data_limit_not_na.balanceUsd_mln/BABD_data_limit_not_na.Limit)*100\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_13764\\1071633976.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[5.68291700e+01 1.45840000e-03 0.00000000e+00 ... 0.00000000e+00\n",
      " 0.00000000e+00 1.82677219e-02]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  BABD_data_work[~BABD_data_work.Limit.isna()] = BABD_data_limit_not_na\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_13764\\1071633976.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[5.68291700e+01 1.45840000e-03 0.00000000e+00 ... 0.00000000e+00\n",
      " 0.00000000e+00 1.82677219e-02]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  BABD_data_work[~BABD_data_work.Limit.isna()] = BABD_data_limit_not_na\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:98: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:43: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['NAM' 'SUEK AG+' 'SUEK AG+' ... 'SUEK RU' 'SUEK RU' 'SUEK RU']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', 'last_merge'] = merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', f'{id_colmn}_merge']\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:98: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_13764\\1071633976.py:100: FutureWarning: The provided callable <built-in function sum> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot_data_for_frame = holding_data.pivot_table(index='bank_name', values='Total', aggfunc=sum, columns='Segment').reset_index()\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_13764\\1071633976.py:104: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '54.36' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Frame_table.loc[Frame_table.bank_name==bank_name,segment_column] = [df_dict_list[x] for x in range(len(df_dict_list)) if df_dict_list[x]['bank_name']==bank_name][0][segment_column]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_13764\\1071633976.py:104: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.61' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Frame_table.loc[Frame_table.bank_name==bank_name,segment_column] = [df_dict_list[x] for x in range(len(df_dict_list)) if df_dict_list[x]['bank_name']==bank_name][0][segment_column]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_13764\\1071633976.py:121: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '9.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_concat.loc[(data_concat.bankCountryCode==country)&(data_concat.bank_name.isna()),'index_copy'] = change_values_index_dict[country]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_13764\\1071633976.py:124: FutureWarning: The provided callable <built-in function sum> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot_data_for_frame = holding_data.pivot_table(index='bankCountryCode', values='Total', aggfunc=sum, columns='Segment').reset_index()\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_13764\\1071633976.py:100: FutureWarning: The provided callable <built-in function sum> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot_data_for_frame = holding_data.pivot_table(index='bank_name', values='Total', aggfunc=sum, columns='Segment').reset_index()\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_13764\\1071633976.py:104: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '141.53' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Frame_table.loc[Frame_table.bank_name==bank_name,segment_column] = [df_dict_list[x] for x in range(len(df_dict_list)) if df_dict_list[x]['bank_name']==bank_name][0][segment_column]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_13764\\1071633976.py:104: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.61' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Frame_table.loc[Frame_table.bank_name==bank_name,segment_column] = [df_dict_list[x] for x in range(len(df_dict_list)) if df_dict_list[x]['bank_name']==bank_name][0][segment_column]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_13764\\1071633976.py:104: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.12' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Frame_table.loc[Frame_table.bank_name==bank_name,segment_column] = [df_dict_list[x] for x in range(len(df_dict_list)) if df_dict_list[x]['bank_name']==bank_name][0][segment_column]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_13764\\1071633976.py:121: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '19.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_concat.loc[(data_concat.bankCountryCode==country)&(data_concat.bank_name.isna()),'index_copy'] = change_values_index_dict[country]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_13764\\1071633976.py:124: FutureWarning: The provided callable <built-in function sum> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot_data_for_frame = holding_data.pivot_table(index='bankCountryCode', values='Total', aggfunc=sum, columns='Segment').reset_index()\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "SELECT *\n",
    "FROM \"RISKACCESS\".\"bankAccountsBalanceDaily\"\n",
    "WHERE \"reportDate\" = (SELECT MAX(\"reportDate\") FROM \"RISKACCESS\".\"bankAccountsBalanceDaily\")\n",
    "\"\"\"\n",
    "bankAccountsBalanceDaily_data = export_from_RISKCUSTOM(query) # export data\n",
    "BABD_data_work = bankAccountsBalanceDaily_data # BABD_data_work,\n",
    "BABD_data_work['balanceUsd_mln'] = BABD_data_work.balanceUsd/10**6 # balanceUsd_mln\n",
    "# balanceUsd_activmoney_market\n",
    "accountStatus_list = ['active', 'mmarket']\n",
    "BABD_data_work['balanceUsd_activmoney_market'] = 0\n",
    "BABD_data_work.loc[BABD_data_work.accountStatus.isin(accountStatus_list), 'balanceUsd_activmoney_market'] = BABD_data_work.loc[BABD_data_work.accountStatus.isin(accountStatus_list), 'balanceUsd_mln']\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT CONCAT(CONCAT(\"bankId\", \"holding\"), \"limitType\") as \"con\", \"activeFrom\", \"bankId\", \"limitType\", \"limit\", \"holding\"\n",
    "FROM \"RISKACCESS\".\"xxmrBankLimits\" \n",
    "WHERE \"limitType\" IN ('Transit', 'Deposit')\n",
    "\"\"\"\n",
    "Limit_export_data = export_from_RISKCUSTOM(query) # export data\n",
    "LE_data_work = Limit_export_data.sort_values(by='activeFrom').drop_duplicates(subset='con', keep='last')  # Unique strings with lasr value for activeFrom\n",
    "# pivot by bankid and mln of limit\n",
    "LE_data_work['H_B_concat'] = LE_data_work.holding + '_' + LE_data_work.bankId\n",
    "LE_data_group = pd.pivot_table(data=LE_data_work, index=['H_B_concat', 'bankId', 'holding'], values='limit', aggfunc='sum').reset_index()\n",
    "LE_data_group.limit = LE_data_group.limit/10**6\n",
    "# merge BABD_data_work and LE_data_group\n",
    "BABD_data_work = BABD_data_work.reset_index(drop=True)\n",
    "BABD_data_work['H_B_concat'] = BABD_data_work.holding + '_' + BABD_data_work.bankId\n",
    "BABD_data_work['Limit'] = BABD_data_work.merge(LE_data_group, how='left', left_on='H_B_concat', right_on='H_B_concat', validate='many_to_one').iloc[:,-1]\n",
    "# Usage and Usage_activmoney_market\n",
    "BABD_data_work['Usage_activmoney_market'] = 0\n",
    "BABD_data_work['Usage'] = 0\n",
    "BABD_data_limit_not_na = BABD_data_work[~BABD_data_work.Limit.isna()]\n",
    "BABD_data_limit_not_na['Usage_activmoney_market'] = (BABD_data_limit_not_na.balanceUsd_activmoney_market/BABD_data_limit_not_na.Limit)*100\n",
    "BABD_data_limit_not_na['Usage'] = (BABD_data_limit_not_na.balanceUsd_mln/BABD_data_limit_not_na.Limit)*100\n",
    "BABD_data_work[~BABD_data_work.Limit.isna()] = BABD_data_limit_not_na\n",
    "BABD_data_work.loc[(BABD_data_work.Usage == np.inf) | (BABD_data_work.Usage.isna()) | (BABD_data_work.Usage == -np.inf), 'Usage'] = 0\n",
    "BABD_data_work.loc[(BABD_data_work.Usage_activmoney_market == np.inf) | (BABD_data_work.Usage_activmoney_market.isna()) | (BABD_data_work.Usage_activmoney_market == -np.inf), 'Usage_activmoney_market'] = 0\n",
    "BABD_data_work['Segment'] = merge_SalesUnits(df=BABD_data_work, merge_col='businessSegmentDetailed', col='buCode') # merge Segment\n",
    "# Bank_name\n",
    "query = \"\"\"SELECT \"bankId\", \"name\", \"country\"\n",
    "FROM \"RISKACCESS\".\"xxmrBankLimitsBanks\"\n",
    "\"\"\"\n",
    "data_xxmrBankLimitsBanks = export_from_RISKCUSTOM(query)\n",
    "data_BLB = data_xxmrBankLimitsBanks.drop_duplicates(subset='bankId').dropna()\n",
    "BABD_data_work['bank_name'] = BABD_data_work.merge(data_BLB, how='left', left_on='bankId', right_on='bankId', validate='many_to_one').iloc[:, -2]\n",
    "BABD_data_work.loc[(BABD_data_work.bank_name.isna()), 'bank_name'] = BABD_data_work.loc[(BABD_data_work.bank_name.isna()), 'bankName']\n",
    "# rounding\n",
    "BABD_data_work[['Usage_activmoney_market','Usage']] = BABD_data_work[['Usage_activmoney_market','Usage']].apply(lambda x:round(x, 1))\n",
    "BABD_data_work[['balanceUsd_mln','balanceUsd_activmoney_market', 'Limit']] = BABD_data_work[['balanceUsd_mln','balanceUsd_activmoney_market', 'Limit']].round(2)\n",
    "\n",
    "### TO EXCEL\n",
    "BABD_data_work = BABD_data_work.rename(columns={'balanceUsd_activmoney_market':'Active', 'balanceUsd_mln':'Total', 'Usage_activmoney_market':'%_active', 'Usage':'%_total'})\n",
    "BABD_data_work = BABD_data_work[(BABD_data_work.Active!=0)&(BABD_data_work.Limit!=0)]\n",
    "# Creating Excel Writer Object from Pandas \n",
    "report_date = str(BABD_data_work.reportDate.max())[:10]\n",
    "# by holding\n",
    "holding_list = BABD_data_work.holding.unique().tolist()\n",
    "for holding in holding_list:\n",
    "    holding_data = BABD_data_work[BABD_data_work.holding == holding].reset_index(drop=True) # holding data\n",
    "    holding_data['Total_bank_name'] = holding_data.groupby('bank_name')['Total'].transform('sum')\n",
    "    # table 1\n",
    "    tabel_bankName = pd.pivot_table(data=holding_data, \n",
    "                    index='bank_name', \n",
    "                    values=['Limit', 'Active', 'Total', '%_active', '%_total'], \n",
    "                    aggfunc={'Limit':'mean', 'Active':'sum', 'Total':'sum', '%_active':'sum', '%_total':'sum'},\n",
    "                    fill_value=0)\\\n",
    "                    .reset_index()\\\n",
    "                    .sort_values(['Active', 'Total'], ascending=False)\n",
    "    # tabel_bankName = tabel_bankName[['bank_name','Limit', 'Active', '%_active', 'Total', '%_total', 'Segment']]\n",
    "    tabel_bankName = tabel_bankName[['bank_name','Limit', 'Active', '%_active', 'Total', '%_total']]\n",
    "    # table 2\n",
    "    table_bankCountryCode = pd.pivot_table(data=holding_data, \n",
    "                    index='bankCountryCode', \n",
    "                    values=['Active', 'Total'], \n",
    "                    aggfunc={'Active':'sum', 'Total':'sum'})\\\n",
    "                    .reset_index()\\\n",
    "                    .sort_values(['Active', 'Total'], ascending=False)\n",
    "    # table 3\n",
    "    table_Segment = pd.pivot_table(data=holding_data, \n",
    "                    index='Segment', \n",
    "                    values=['Active', 'Total'], \n",
    "                    aggfunc={'Active':'sum', 'Total':'sum'})\\\n",
    "                    .reset_index()\\\n",
    "                    .sort_values(['Active', 'Total'], ascending=False)\n",
    "    # sheet 3\n",
    "    # Create the frame in the right order \n",
    "    tabel_bankName_2 = pd.pivot_table(data=holding_data, \n",
    "                    index=['bank_name','bankCountryCode'], \n",
    "                    values=['Active', 'Total'], \n",
    "                    aggfunc={'Active':'sum', 'Total':'sum'},\n",
    "                    fill_value=0)\\\n",
    "                    .reset_index()\\\n",
    "                    .sort_values(['Active', 'Total'], ascending=False)\n",
    "    Frame_table = table_bankCountryCode.merge(tabel_bankName_2, how='left', left_on='bankCountryCode', right_on='bankCountryCode').dropna()\n",
    "    # create columns\n",
    "    new_columns = table_Segment.Segment.values.tolist()\n",
    "    Frame_table = Frame_table.reindex(columns=Frame_table.columns.tolist() + new_columns, fill_value=0)\n",
    "    Frame_table = Frame_table.drop(['Active_x','Total_x'], axis=1).rename(columns={'Active_y':'Active','Total_y':'Total'})\n",
    "    # fill values\n",
    "    pivot_data_for_frame = holding_data.pivot_table(index='bank_name', values='Total', aggfunc=sum, columns='Segment').reset_index()\n",
    "    df_dict_list = pivot_data_for_frame.to_dict(orient='records')\n",
    "    for bank_name in Frame_table.bank_name:\n",
    "        for segment_column in Frame_table.iloc[:, 4:].columns:\n",
    "            Frame_table.loc[Frame_table.bank_name==bank_name,segment_column] = [df_dict_list[x] for x in range(len(df_dict_list)) if df_dict_list[x]['bank_name']==bank_name][0][segment_column]\n",
    "    # filter banks with empty Active and Total\n",
    "    empty_banks_list = tabel_bankName[(tabel_bankName.Active==0)&(tabel_bankName.Total==0)].bank_name.unique().tolist()\n",
    "    Frame_table = Frame_table[~Frame_table.bank_name.isin(empty_banks_list)].fillna(0)\n",
    "    ### add final country rows\n",
    "    Frame_table = Frame_table.reset_index(drop=True)\n",
    "    table_bankCountryCode_for_concat = table_bankCountryCode[table_bankCountryCode.bankCountryCode.isin(Frame_table.bankCountryCode.unique().tolist())].reset_index(drop=True)\n",
    "    data_concat = pd.concat([Frame_table,table_bankCountryCode_for_concat])\n",
    "    # work with index\n",
    "    data_concat['index_copy'] = data_concat.index\n",
    "    change_values_index_dict = {}\n",
    "    for table_index in range(1,Frame_table.shape[0]):\n",
    "        if Frame_table.loc[table_index, 'bankCountryCode']!=Frame_table.loc[(table_index-1), 'bankCountryCode']:\n",
    "            change_values_index_dict[Frame_table.loc[(table_index-1), 'bankCountryCode']] = table_index-0.5\n",
    "    change_values_index_dict[Frame_table.loc[len(Frame_table)-1, 'bankCountryCode']] = len(Frame_table)-0.5\n",
    "    # change index\n",
    "    for country in list(change_values_index_dict.keys()):\n",
    "        data_concat.loc[(data_concat.bankCountryCode==country)&(data_concat.bank_name.isna()),'index_copy'] = change_values_index_dict[country]\n",
    "    Frame_table = data_concat.set_index('index_copy').sort_index()\n",
    "    # fill values\n",
    "    pivot_data_for_frame = holding_data.pivot_table(index='bankCountryCode', values='Total', aggfunc=sum, columns='Segment').reset_index()\n",
    "    df_dict_list = pivot_data_for_frame.to_dict(orient='records')\n",
    "    for bankCountryCode in Frame_table.bankCountryCode.unique().tolist():\n",
    "        for segment_column in Frame_table.iloc[:, 4:].columns:\n",
    "            Frame_table.loc[(Frame_table.bankCountryCode==bankCountryCode)&(Frame_table.bank_name.isna()),segment_column] = [df_dict_list[x] for x in range(len(df_dict_list)) if df_dict_list[x]['bankCountryCode']==bankCountryCode][0][segment_column]\n",
    "\n",
    "    \n",
    "    # tabel_bankName['Segment'] = tabel_bankName.merge(holding_data, how='left', left_on='bank_name', right_on='bank_name')['Segment']\n",
    "    # table_bankCountryCode['Segment'] = table_bankCountryCode.merge(holding_data, how='left', left_on='', right_on='')\n",
    "\n",
    "    if holding == 'SUEK':\n",
    "        tabel_bankName_SUEK = tabel_bankName\n",
    "        table_bankCountryCode_SUEK = table_bankCountryCode\n",
    "        table_Segment_SUEK = table_Segment\n",
    "        Frame_table_SUEK = Frame_table\n",
    "        change_values_index_dict_SUEK = change_values_index_dict\n",
    "    else:\n",
    "        tabel_bankName_Ech = tabel_bankName\n",
    "        tabel_bankName_Ech = tabel_bankName_Ech[~tabel_bankName_Ech.bank_name.str.contains('Urbo')] # фильтр на конкретный банк\n",
    "        table_bankCountryCode_Ech = table_bankCountryCode\n",
    "        table_Segment_Ech = table_Segment\n",
    "        Frame_table_Ech = Frame_table\n",
    "        change_values_index_dict_Ech = change_values_index_dict\n",
    "    # to excel\n",
    "    if Print_to_excel == True:\n",
    "        Output_file = '_'.join([report_date, holding,'limits_report.xlsx'])\n",
    "        writer = pd.ExcelWriter(Output_file, engine='openpyxl')  \n",
    "        workbook=writer.book\n",
    "        pd.DataFrame({'holding':f'{holding} (in MUSD)'}, index=[1]).to_excel(writer, sheet_name=holding, index=False, header=False)\n",
    "        tabel_bankName.to_excel(writer, sheet_name=holding, index=False, startrow=1)\n",
    "        table_bankCountryCode.to_excel(writer, sheet_name=holding, startcol=8, index=False, startrow=1)\n",
    "        table_Segment.to_excel(writer, sheet_name=holding, startcol=13, index=False, startrow=1)\n",
    "        writer.close()\n",
    "\n",
    "        # writing new files for segments\n",
    "        if holding=='EUROCHEM':\n",
    "            sheets_list_Ech = ['EUROCHEM']\n",
    "            sheets_dict_Ech = {'EUROCHEM':Output_file}\n",
    "            for filt in [['SAM'], ['NAM'], ['EUROPE', 'EUROPE distributors and plants', 'SUEK AG+']]:\n",
    "                sheet_n = f'{holding}_{filt[0]}'\n",
    "                sheets_list_Ech = sheets_list_Ech + [sheet_n]\n",
    "\n",
    "                Output_file_filt = '_'.join([report_date, holding, filt[0],'limits_report.xlsx'])\n",
    "                sheets_dict_Ech[f'EUROCHEM_{filt[0]}'] = Output_file_filt\n",
    "                writer = pd.ExcelWriter(Output_file_filt, engine='openpyxl')  \n",
    "                workbook=writer.book\n",
    "\n",
    "                pd.DataFrame({'holding':f'{holding} (in MUSD)'}, index=[1]).to_excel(writer, sheet_name=sheet_n, index=False, header=False)\n",
    "                \n",
    "                holding_data.Segment = holding_data.Segment.replace({'TRADING Europe':'EUROPE'})\n",
    "                tabel_bankName_filt = holding_data[holding_data.Segment.isin(filt)]\n",
    "                tabel_bankName_filt_pivot = pd.pivot_table(data=tabel_bankName_filt, index='bank_name', \n",
    "                                                values=['Limit', 'Active', 'Total_bank_name'], \n",
    "                                                aggfunc={'Limit':'mean', 'Active':'sum', 'Total_bank_name':'mean'},\n",
    "                                                fill_value=0)\\\n",
    "                                                .reset_index()\\\n",
    "                                                .sort_values(['Active', 'Total_bank_name'], ascending=False)\n",
    "                tabel_bankName_filt_pivot['%_active'] = (tabel_bankName_filt_pivot.Active/tabel_bankName_filt_pivot.Limit)*100\n",
    "                tabel_bankName_filt_pivot['%_total'] = (tabel_bankName_filt_pivot.Total_bank_name/tabel_bankName_filt_pivot.Limit)*100\n",
    "                tabel_bankName_filt_pivot[['%_total', '%_active']] = tabel_bankName_filt_pivot[['%_total', '%_active']].fillna(0)\n",
    "                tabel_bankName_filt_pivot.loc[tabel_bankName_filt_pivot['%_active']==np.inf, '%_active'] = 0\n",
    "                tabel_bankName_filt_pivot.loc[tabel_bankName_filt_pivot['%_total']==np.inf, '%_total'] = 0\n",
    "                tabel_bankName_filt_pivot = tabel_bankName_filt_pivot.rename(columns={'Total_bank_name':'Total'})\n",
    "                tabel_bankName_filt_pivot = tabel_bankName_filt_pivot[['bank_name','Limit', 'Active', '%_active', 'Total', '%_total']]\n",
    "                \n",
    "                tabel_bankName_filt_pivot.to_excel(writer, sheet_name=sheet_n, index=False, startrow=1)\n",
    "                # table_bankCountryCode.to_excel(writer, sheet_name=sheet_n, startcol=8, index=False, startrow=1)\n",
    "                # table_Segment.to_excel(writer, sheet_name=sheet_n, startcol=13, index=False, startrow=1)\n",
    "                writer.close()\n",
    "\n",
    "        new_list(bankAccountsBalanceDaily_data[bankAccountsBalanceDaily_data.holding==holding], sheet_name='data', output_file=Output_file)\n",
    "        new_list(Frame_table, sheet_name='Banks_to_segments_(Total)', output_file=Output_file)\n",
    "        if holding == 'SUEK':\n",
    "            Output_file_SUEK = Output_file\n",
    "        else:\n",
    "            Output_file_Ech = Output_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NAM', 'CIS', 'RUSSIA', 'TRADING Europe', 'SAM',\n",
       "       'TRADING Agro Asia', 'TRADING UAE',\n",
       "       'EUROPE distributors and plants', 'SUEK AG+', 'SST', 'SPV',\n",
       "       'TRADING Shenzhen', 'NTC', 'SUEK RU', 'BSC', 'SGC', 'External'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BABD_data_work.loc[BABD_data_work.Segment=='External',['holding','buCode','buName','Segment']]\n",
    "BABD_data_work.loc[:,'Segment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FORMAT\n",
    "if Print_to_excel == True:\n",
    "    SUEK_tables_list = [tabel_bankName_SUEK, table_bankCountryCode_SUEK, table_Segment_SUEK, Frame_table_SUEK]\n",
    "    Ech_tabels_list = [tabel_bankName_Ech, table_bankCountryCode_Ech, table_Segment_Ech, Frame_table_Ech]\n",
    "            \n",
    "    holdind = ''\n",
    "    Output_file = ''\n",
    "    len_A_dict = {}\n",
    "    for holding in holding_list:\n",
    "        if holding == 'SUEK':\n",
    "            tables_list = SUEK_tables_list\n",
    "            Output_file = Output_file_SUEK\n",
    "            sheet_list = ['SUEK']\n",
    "            sheet_dict = {'SUEK': Output_file_SUEK}\n",
    "        else:\n",
    "            tables_list = Ech_tabels_list\n",
    "            Output_file = Output_file_Ech\n",
    "            sheet_list = sheets_list_Ech\n",
    "            sheet_dict = sheets_dict_Ech\n",
    "\n",
    "        # open file\n",
    "        for sheet_n in sheet_list:\n",
    "            Output_file = f'{sheet_dict[sheet_n]}'\n",
    "            wb = openpyxl.load_workbook(Output_file)\n",
    "            ws = wb[sheet_n]\n",
    "            \n",
    "            len_A=0\n",
    "            for row in range(3,10000):\n",
    "                if type(ws[f'A{row}'].value) is not str:\n",
    "                    len_A = row-1\n",
    "                    break\n",
    "            len_A_dict[sheet_n] = len_A\n",
    "            data = []\n",
    "            for row in ws[f'A2:F{len_A}']:\n",
    "                row_data = [cell.value for cell in row]\n",
    "                data.append(row_data)\n",
    "            data = pd.DataFrame(data)\n",
    "            data.columns = data.iloc[0,:]\n",
    "            tables_list[0] = data.iloc[1:,:]\n",
    "\n",
    "            # color\n",
    "            color_areas_list = [f\"C2:C{len(tables_list[0])+2}\", f\"J2:J{len(tables_list[1])+2}\", f\"O2:O{len(tables_list[2])+2}\"]\n",
    "            cell_color = PatternFill(start_color='00FFCC99', end_color='00FFCC99', fill_type = \"solid\")\n",
    "            for color_area in color_areas_list:\n",
    "                for row in ws[color_area]:\n",
    "                    for cell in row:\n",
    "                        cell.fill = cell_color\n",
    "                if sheet_n!=holding:\n",
    "                    break\n",
    "            cell_color = PatternFill(start_color='00CCFFCC', end_color='00CCFFCC', fill_type = \"solid\")\n",
    "            for row in ws['A1:F1']:\n",
    "                for cell in row:\n",
    "                    cell.fill = cell_color\n",
    "                    cell.font = Font(bold=True)\n",
    "            # Borders         \n",
    "            medium = Side(border_style=\"medium\", color=\"000000\")\n",
    "            right_line_areas_list = [f\"F2:F{len(tables_list[0])+2}\", f\"K2:K{len(tables_list[1])+2}\", f\"P2:P{len(tables_list[2])+2}\"]\n",
    "            for right_line_area in right_line_areas_list:\n",
    "                for row in ws[right_line_area]:\n",
    "                    for cell in row:\n",
    "                        cell.border = Border(top=None, left=None, right=medium, bottom=None)\n",
    "                if sheet_n!=holding:\n",
    "                    break\n",
    "            left_line_areas_list = [f\"A2:A{len(tables_list[0])+2}\", f\"I2:I{len(tables_list[1])+2}\", f\"N2:N{len(tables_list[2])+2}\"]\n",
    "            for left_line_area in left_line_areas_list:\n",
    "                for row in ws[left_line_area]:\n",
    "                    for cell in row:\n",
    "                        cell.border = Border(top=None, left=medium, right=medium, bottom=None)\n",
    "                if sheet_n!=holding:\n",
    "                    break                        \n",
    "            top_line_areas_list = ['A2:F2', 'I2:K2', 'N2:P2']\n",
    "            for top_line_area in top_line_areas_list:\n",
    "                for row in ws[top_line_area]:\n",
    "                    for cell in row:\n",
    "                        cell.border = Border(top=medium, left=medium, right=medium, bottom=medium)\n",
    "                if sheet_n!=holding:\n",
    "                    break\n",
    "            bottom_line_areas_list = [f'A{len(tables_list[0])+2}:F{len(tables_list[0])+2}', f'I{len(tables_list[1])+2}:K{len(tables_list[1])+2}', f'N{len(tables_list[2])+2}:P{len(tables_list[2])+2}']\n",
    "            for bottom_line_area in bottom_line_areas_list:\n",
    "                for row in ws[bottom_line_area]:\n",
    "                    for cell in row:\n",
    "                        cell.border = Border(top=None, bottom=medium)\n",
    "                if sheet_n!=holding:\n",
    "                    break\n",
    "            # font color errors\n",
    "            tables_list[0] = tables_list[0].reset_index(drop=True)\n",
    "            # tables with deviations\n",
    "            significant_deviation = tables_list[0][(((tables_list[0].Active - tables_list[0].Limit) > tables_list[0].Limit*0.1) | ((tables_list[0].Active - tables_list[0].Limit) > 10)) & ((tables_list[0].Active - tables_list[0].Limit) > 0)]\n",
    "            significant_deviation_index_liist = significant_deviation.index.tolist()\n",
    "            insignificant_deviation = tables_list[0][(((tables_list[0].Active - tables_list[0].Limit) <= tables_list[0].Limit*0.1) & ((tables_list[0].Active - tables_list[0].Limit) <= 10)) & ((tables_list[0].Active - tables_list[0].Limit) > 0)]\n",
    "            insignificant_deviation_index_liist = insignificant_deviation.index.tolist()\n",
    "            # areas lists\n",
    "            significant_deviation_areas_liist = [f'A{x+3}:F{x+3}' for x in significant_deviation_index_liist] # red\n",
    "            insignificant_deviation_areas_liist = [f'A{x+3}:F{x+3}' for x in insignificant_deviation_index_liist] # orange\n",
    "            # color areas\n",
    "            cell_color = PatternFill(start_color='00FF8080', end_color='00FF8080', fill_type = \"solid\")\n",
    "            for color_area in significant_deviation_areas_liist:\n",
    "                for row in ws[color_area]:\n",
    "                    for cell in row:\n",
    "                        cell.fill = cell_color # red\n",
    "            for color_area in insignificant_deviation_areas_liist:\n",
    "                for row in ws[color_area]:\n",
    "                    for cell in row:\n",
    "                        cell.font = Font(color=\"00FF9900\") # orange\n",
    "            # Weight of olumns\n",
    "            ws.column_dimensions['A'].width = 29\n",
    "            ws.column_dimensions['B'].width = 8\n",
    "            ws.column_dimensions['C'].width = 12\n",
    "            ws.column_dimensions['D'].width = 8\n",
    "            ws.column_dimensions['E'].width = 8\n",
    "            ws.column_dimensions['F'].width = 8\n",
    "            ws.column_dimensions['G'].width = 5\n",
    "            ws.column_dimensions['H'].width = 5\n",
    "            ws.column_dimensions['I'].width = 16\n",
    "            ws.column_dimensions['J'].width = 8\n",
    "            ws.column_dimensions['K'].width = 8\n",
    "            ws.column_dimensions['L'].width = 5\n",
    "            ws.column_dimensions['M'].width = 5\n",
    "            ws.column_dimensions['N'].width = 28\n",
    "            ws.column_dimensions['O'].width = 8\n",
    "            ws.column_dimensions['P'].width = 8\n",
    "            # Rounding\n",
    "            rounding_2_numbers_list = [f'C3:C{len(tables_list[0])+2}', f'E3:E{len(tables_list[0])+2}', f'J3:K{len(tables_list[1])+2}', f'O3:P{len(tables_list[2])+2}']\n",
    "            rounding_1_numbers_list = [f'D3:D{len(tables_list[0])+2}', f'F3:F{len(tables_list[0])+2}']\n",
    "            for color_area in rounding_2_numbers_list:\n",
    "                for row in ws[color_area]:\n",
    "                    for cell in row:\n",
    "                        cell.number_format = '0.00'\n",
    "            for color_area in rounding_1_numbers_list:\n",
    "                for row in ws[color_area]:\n",
    "                    for cell in row:\n",
    "                        cell.number_format = '0.0'\n",
    "            # close file\n",
    "            wb.save(Output_file)\n",
    "            wb.close() \n",
    "            \n",
    "            if sheet_n==holding:\n",
    "                # Format 3-th sheet\n",
    "                # open file\n",
    "                wb = openpyxl.load_workbook(Output_file)\n",
    "                ws = wb['Banks_to_segments_(Total)']\n",
    "                # Frame table line after countries\n",
    "                # Number of strings to line\n",
    "                change_values_index_list = []\n",
    "                tables_list[3] = tables_list[3].reset_index(drop=True)\n",
    "                for table_index in range(1,tables_list[3].shape[0]):\n",
    "                    if tables_list[3].loc[table_index, 'bankCountryCode']!=tables_list[3].loc[(table_index-1), 'bankCountryCode']:\n",
    "                        change_values_index_list += [table_index+1]\n",
    "                change_values_index_list += [len(tables_list[3])+1]\n",
    "                # Letter of the end of the table\n",
    "                letters_dict = {i:chr(i+64) for i in range(1,27)}\n",
    "                letter_last_column = letters_dict[tables_list[3].shape[1]]\n",
    "                # right lines \n",
    "                lines_areas = [f'{i}1:{i}{tables_list[3].shape[0]+1}' for i in ['B','D',letter_last_column]]\n",
    "                for bottom_line_area in lines_areas:\n",
    "                    for row in ws[bottom_line_area]:\n",
    "                        for cell in row:\n",
    "                            cell.border = Border(top=cell.border.top, left=cell.border.left, right=medium, bottom=cell.border.bottom)\n",
    "                # bottom lines\n",
    "                lines_areas = [f'A{i}:{letter_last_column}{i}' for i in change_values_index_list]+[f'A1:{letter_last_column}1']\n",
    "                for bottom_line_area in lines_areas:\n",
    "                    for row in ws[bottom_line_area]:\n",
    "                        for cell in row:\n",
    "                            cell.border = Border(top=cell.border.top, left=cell.border.left, right=cell.border.right, bottom=medium)\n",
    "                # color of total by country \n",
    "                color_areas = [f'A{i}:{letter_last_column}{i}' for i in change_values_index_list]\n",
    "                # close file\n",
    "                cell_color = PatternFill(start_color='00CCFFCC', end_color='00CCFFCC', fill_type = \"solid\")\n",
    "                for color_area in color_areas:\n",
    "                    for row in ws[color_area]:\n",
    "                        for cell in row:\n",
    "                                cell.fill = cell_color\n",
    "                                cell.font = Font(bold=True)\n",
    "                # Rounding\n",
    "                for row in ws[f'C2:{letter_last_column}{len(tables_list[3])+1}']:\n",
    "                    for cell in row:\n",
    "                        cell.number_format = '0.00'\n",
    "                # Weight of olumns\n",
    "                ws.column_dimensions['B'].width = 29\n",
    "        \n",
    "                wb.save(Output_file)\n",
    "                wb.close() \n",
    "        # if holding == 'EUROCHEM':\n",
    "        #     len_A_dict_Ech = len_A_dict\n",
    "        # else:\n",
    "        #     len_A_dict_SUEK = len_A_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Отправка письма\n",
    "holdind = ''\n",
    "Output_file = ''\n",
    "top = 0\n",
    "for holding in holding_list:\n",
    "    if holding == 'SUEK':\n",
    "        Output_file = Output_file_SUEK\n",
    "        sheet_list = ['SUEK']\n",
    "        sheet_dict = {'SUEK': Output_file_SUEK}\n",
    "        top = 10\n",
    "    else:\n",
    "        Output_file = Output_file_Ech\n",
    "        sheet_list = sheets_list_Ech\n",
    "        sheet_dict = sheets_dict_Ech\n",
    "        top = 30\n",
    "\n",
    "    for sheet_n in sheet_list:\n",
    "        # create image\n",
    "        Output_file = sheet_dict[sheet_n]\n",
    "        client = win32com.client.Dispatch(\"Excel.Application\")\n",
    "        wb = client.Workbooks.Open('\\\\'.join([os.getcwd(),Output_file]))\n",
    "        ws = wb.Worksheets(sheet_n)\n",
    "        if sheet_n == holding:\n",
    "            field = f\"A1:P{top}\"\n",
    "        elif len_A_dict[sheet_n]<top:\n",
    "            field = f\"A1:F{len_A_dict[sheet_n]}\"\n",
    "        else:    \n",
    "            field = f\"A1:F{top}\"\n",
    "        ws.Range(field).CopyPicture(Format = 2) # screen area\n",
    "        img = ImageGrab.grabclipboard()\n",
    "        img.save(f'{holding}.png')\n",
    "        wb.Close() # иначе табл будет открыта\n",
    "        client.Quit()\n",
    "        # create mail\n",
    "        mailItem = olApp.CreateItem(0)\n",
    "        mailItem.BodyFormat = 3\n",
    "        # mail title\n",
    "        mailItem.Subject = f'{sheet_n} bank limits for {report_date}' # mail head\n",
    "        # mail body\n",
    "        html_body = f\"\"\"<html><body><p>Dear colleagues,<br><br>\n",
    "        Please find attached {holding} daily report on bank limits for {report_date}:<br><br>\n",
    "        <img src=\"{(os.path.join(os.getcwd(), holding))}.png\"><br><br>    \n",
    "        Please follow the attached file for details<br><br>\n",
    "        Best regards,<br>\n",
    "        {signature}</p></body></html>\"\"\"\n",
    "        if holding == 'SUEK':\n",
    "            mailItem.To = mail_to_Suek # mail to\n",
    "        else:\n",
    "            to_list = [mail_to_Ech, mail_ECH_SAM, mail_ECH_NAM, mail_ECH_Europe]\n",
    "            to_ech_dict = {x:y for x,y in zip(sheets_list_Ech, to_list)}\n",
    "            mailItem.To = to_ech_dict[sheet_n] # mail to\n",
    "            # mail attachment\n",
    "        mail_attachment = Output_file\n",
    "    \n",
    "    \n",
    "        mailItem._oleobj_.Invoke(*(64209, 0, 8, 0, olNS.Accounts.Item(mail_from)))\n",
    "        mailItem.Attachments.Add(os.path.join(os.getcwd(), mail_attachment))\n",
    "        mailItem.HTMLBody = html_body\n",
    "        mailItem.Sensitivity  = 2\n",
    "    \n",
    "        # mailItem.Save()\n",
    "        if Display_mail == True: ### DISPLAY\n",
    "            mailItem.Display()\n",
    "        if Send_mail == True: ### SEND\n",
    "            mailItem.Send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holding</th>\n",
       "      <th>buCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>SUEK</td>\n",
       "      <td>1Y00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     holding buCode\n",
       "2989    SUEK   1Y00"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_map = BABD_data_work.loc[BABD_data_work['Segment'] == 'External', ['holding', 'buCode']].drop_duplicates()\n",
    "manual_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"Limits\" was finished\n"
     ]
    }
   ],
   "source": [
    "print('The \"Limits\" was finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
