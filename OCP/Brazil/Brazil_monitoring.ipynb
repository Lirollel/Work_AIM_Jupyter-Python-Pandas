{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\KlimovaAnnaA\\\\Documents\\\\MyFiles\\\\Projects\\\\Working_attributes\")\n",
    "from Imports import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def for checking str in every file\n",
    "def find_str_in_all_files(str_to_find):\n",
    "    in_dict = {}\n",
    "    for count in range(len(files_df)):\n",
    "        str_to_find_lower = str_to_find.strip().lower()\n",
    "        file = files_df.loc[count,'files']\n",
    "        data = pd.read_excel(f'{files_df.loc[count,\"folder\"]}\\\\{file}', sheet_name=sheet_name)\n",
    "        try:\n",
    "            str_index = data[data.apply(lambda row: row.astype(str).str.lower().str.contains(str_to_find_lower).any(), axis=1)].index.item()\n",
    "            in_dict[file] = str_index\n",
    "        except:\n",
    "            continue\n",
    "    return files_df.shape[0], len(in_dict.keys()), in_dict\n",
    "\n",
    "# def for finfing str index\n",
    "def find_id_str(str_to_find):\n",
    "    str_to_find_lower = str_to_find.strip().lower()\n",
    "    id_str = new_data[new_data.apply(lambda row: row.astype(str).str.lower().str.contains(str_to_find_lower).any(), axis=1)].index.item()\n",
    "    return id_str\n",
    "\n",
    "def diff_by_cols(data_col_names, data_merge, count_start_col=1, data_for_cols=True):\n",
    "    \n",
    "    if data_for_cols==False:\n",
    "        cols_list = ['Value']\n",
    "    else:\n",
    "        # cols lisr without name col (first)\n",
    "        cols_list = data_col_names.columns.tolist()[count_start_col:]\n",
    "\n",
    "    for col in cols_list:\n",
    "        # choose only cols with previous col in name\n",
    "        col_cols_list = [x for x,y in zip(data_merge.columns,data_merge.columns.str.contains(col)) if y==True]\n",
    "        assert len(col_cols_list) == 2\n",
    "        # print diff\n",
    "        data_merge[f'{col}_diff'] = -1*(data_merge[col_cols_list[0]] - data_merge[col_cols_list[1]])\n",
    "        # print pct diff\n",
    "        data_merge[f'{col}_pct_diff'] = 0 \n",
    "        # condition = abs(data_merge[[col_cols_list[0],col_cols_list[1]]]).max(axis=1)!=0\n",
    "        # data_merge.loc[condition, f'{col}_pct_diff'] = data_merge.loc[condition,f'{col}_diff'] / abs(data_merge.loc[condition,[col_cols_list[0],col_cols_list[1]]]).max(axis=1)\n",
    "        condition = data_merge[col_cols_list[0]]!=0\n",
    "        data_merge.loc[condition, f'{col}_pct_diff'] = abs(data_merge.loc[condition,f'{col}_diff'] / data_merge.loc[condition,col_cols_list[0]])\n",
    "        data_merge[f'{col}_pct_diff'] = np.sign(data_merge[f'{col}_diff']) * data_merge[f'{col}_pct_diff']\n",
    "\n",
    "    return data_merge\n",
    "\n",
    "def del_null_data(data):\n",
    "    list_to_del = [np.nan, '0', 0]\n",
    "    # del empty rows\n",
    "    data = data[(~data.isin(list_to_del)).any(axis=1)]\n",
    "    # del empty cols\n",
    "    cols_list = (~data.isin(list_to_del)).any(axis=0)\n",
    "    cols_list = cols_list[cols_list==True].index.tolist()\n",
    "    data = data[cols_list]\n",
    "    return data\n",
    "\n",
    "def data_to_parts(data,need_to_name=False):\n",
    "    string_to_find = 'TOTAL'\n",
    "    string_to_find = string_to_find.strip().lower()\n",
    "    try:\n",
    "        assert data.iloc[0,5].strip().lower() == string_to_find\n",
    "        part_col = 6\n",
    "    except:\n",
    "        part_col = 5\n",
    "    asserts_part = data.iloc[:,:part_col]\n",
    "    asserts_part.columns = ['name'] + asserts_part.iloc[0,:].tolist()[1:]\n",
    "    if need_to_name == True:\n",
    "        asserts_part['class_name_1'] = 'Assets'\n",
    "        asserts_part = asserts_part.iloc[2:,:]\n",
    "    else:\n",
    "        asserts_part = asserts_part.iloc[1:,:]\n",
    "\n",
    "    liabilities_part = data.iloc[:,part_col:part_col+part_col]\n",
    "    liabilities_part.columns = ['name'] + liabilities_part.iloc[0,:].tolist()[1:]\n",
    "    if need_to_name == True:\n",
    "        liabilities_part['class_name_1'] = 'Liabilities and equity'\n",
    "        liabilities_part = liabilities_part.iloc[2:,:]\n",
    "    else:\n",
    "        liabilities_part = liabilities_part.iloc[1:,:]\n",
    "\n",
    "    data = pd.concat([asserts_part,liabilities_part],axis=0).reset_index(drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_to_excel = True\n",
    "\n",
    "sheet_name = 'FX Exposure_Balance Sheet'\n",
    "month = ['nov','dec']\n",
    "month = month[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BRFHRG FX Exposure 02.12.2024 - With pnl  Tax Credit - New model.xlsx',\n",
       " 'BRFTO FX Exposure Model 02.12.2024 - With Pnl & Tax Credit -New Model.xlsx',\n",
       " 'BRSFT FX Exposure Model 02.12.2024 - With Pnl & Tax Credit.xlsx',\n",
       " 'BRFHRG FX Exposure 03.12.2024 - With pnl  Tax Credit - New model.xlsx',\n",
       " 'BRFTO FX Exposure Model 03.12.2024 - With Pnl & Tax Credit -New Model.xlsx',\n",
       " 'BRSFT FX Exposure Model 03.12.2024 - With Pnl & Tax Credit.xlsx']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = [x for x in os.listdir() if month in x]\n",
    "files_list = []\n",
    "folders_for_df = []\n",
    "for count in range(len(folders)):\n",
    "    files_folder_list = os.listdir(f'{folders[count]}')\n",
    "    files_folder_list = [x for x in files_folder_list if '~' not in x]\n",
    "    files_list += files_folder_list\n",
    "    folders_for_df += [folders[count] for x in range(len(files_folder_list))]\n",
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>folder</th>\n",
       "      <th>day</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRFHRG FX Exposure 02.12.2024 - With pnl  Tax ...</td>\n",
       "      <td>2 dec</td>\n",
       "      <td>02.12.2024</td>\n",
       "      <td>BRFHRG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRFTO FX Exposure Model 02.12.2024 - With Pnl ...</td>\n",
       "      <td>2 dec</td>\n",
       "      <td>02.12.2024</td>\n",
       "      <td>BRFTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRSFT FX Exposure Model 02.12.2024 - With Pnl ...</td>\n",
       "      <td>2 dec</td>\n",
       "      <td>02.12.2024</td>\n",
       "      <td>BRSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRFHRG FX Exposure 03.12.2024 - With pnl  Tax ...</td>\n",
       "      <td>3 dec</td>\n",
       "      <td>03.12.2024</td>\n",
       "      <td>BRFHRG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRFTO FX Exposure Model 03.12.2024 - With Pnl ...</td>\n",
       "      <td>3 dec</td>\n",
       "      <td>03.12.2024</td>\n",
       "      <td>BRFTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BRSFT FX Exposure Model 03.12.2024 - With Pnl ...</td>\n",
       "      <td>3 dec</td>\n",
       "      <td>03.12.2024</td>\n",
       "      <td>BRSFT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               files folder         day  \\\n",
       "0  BRFHRG FX Exposure 02.12.2024 - With pnl  Tax ...  2 dec  02.12.2024   \n",
       "1  BRFTO FX Exposure Model 02.12.2024 - With Pnl ...  2 dec  02.12.2024   \n",
       "2  BRSFT FX Exposure Model 02.12.2024 - With Pnl ...  2 dec  02.12.2024   \n",
       "3  BRFHRG FX Exposure 03.12.2024 - With pnl  Tax ...  3 dec  03.12.2024   \n",
       "4  BRFTO FX Exposure Model 03.12.2024 - With Pnl ...  3 dec  03.12.2024   \n",
       "5  BRSFT FX Exposure Model 03.12.2024 - With Pnl ...  3 dec  03.12.2024   \n",
       "\n",
       "   company  \n",
       "0  BRFHRG   \n",
       "1   BRFTO   \n",
       "2   BRSFT   \n",
       "3  BRFHRG   \n",
       "4   BRFTO   \n",
       "5   BRSFT   "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_df = pd.DataFrame({'files':files_list, 'folder':folders_for_df})\n",
    "files_df['day'] = files_df.files.str.extract(r'([0-9]{2}.[0-9]{2}.[0-9]{4})')\n",
    "files_df['company'] = files_df.files.str.extract(r'(BR\\w* )')\n",
    "files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files_old</th>\n",
       "      <th>folder_old</th>\n",
       "      <th>day_old</th>\n",
       "      <th>company</th>\n",
       "      <th>files_new</th>\n",
       "      <th>folder_new</th>\n",
       "      <th>day_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRFHRG FX Exposure 02.12.2024 - With pnl  Tax ...</td>\n",
       "      <td>2 dec</td>\n",
       "      <td>02.12.2024</td>\n",
       "      <td>BRFHRG</td>\n",
       "      <td>BRFHRG FX Exposure 03.12.2024 - With pnl  Tax ...</td>\n",
       "      <td>3 dec</td>\n",
       "      <td>03.12.2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRFTO FX Exposure Model 02.12.2024 - With Pnl ...</td>\n",
       "      <td>2 dec</td>\n",
       "      <td>02.12.2024</td>\n",
       "      <td>BRFTO</td>\n",
       "      <td>BRFTO FX Exposure Model 03.12.2024 - With Pnl ...</td>\n",
       "      <td>3 dec</td>\n",
       "      <td>03.12.2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRSFT FX Exposure Model 02.12.2024 - With Pnl ...</td>\n",
       "      <td>2 dec</td>\n",
       "      <td>02.12.2024</td>\n",
       "      <td>BRSFT</td>\n",
       "      <td>BRSFT FX Exposure Model 03.12.2024 - With Pnl ...</td>\n",
       "      <td>3 dec</td>\n",
       "      <td>03.12.2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           files_old folder_old     day_old  \\\n",
       "0  BRFHRG FX Exposure 02.12.2024 - With pnl  Tax ...      2 dec  02.12.2024   \n",
       "1  BRFTO FX Exposure Model 02.12.2024 - With Pnl ...      2 dec  02.12.2024   \n",
       "2  BRSFT FX Exposure Model 02.12.2024 - With Pnl ...      2 dec  02.12.2024   \n",
       "\n",
       "   company                                          files_new folder_new  \\\n",
       "0  BRFHRG   BRFHRG FX Exposure 03.12.2024 - With pnl  Tax ...      3 dec   \n",
       "1   BRFTO   BRFTO FX Exposure Model 03.12.2024 - With Pnl ...      3 dec   \n",
       "2   BRSFT   BRSFT FX Exposure Model 03.12.2024 - With Pnl ...      3 dec   \n",
       "\n",
       "      day_new  \n",
       "0  03.12.2024  \n",
       "1  03.12.2024  \n",
       "2  03.12.2024  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_df_merge = files_df.merge(files_df, on='company', suffixes=['_old','_new'])\n",
    "files_df_couple = files_df_merge[(files_df_merge.day_old!=files_df_merge.day_new)&(files_df_merge.day_old<files_df_merge.day_new)]\n",
    "files_df_couple = files_df_couple.reset_index(drop=True)\n",
    "files_df_couple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 dec\\BRFHRG FX Exposure 02.12.2024 - With pnl  Tax Credit - New model.xlsx\n",
      "3 dec\\BRFHRG FX Exposure 03.12.2024 - With pnl  Tax Credit - New model.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  asserts_part['class_name_1'] = 'Assets'\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  liabilities_part['class_name_1'] = 'Liabilities and equity'\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:144: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Current assets' 'Non-current assets' 'Current liabilities'\n",
      " 'Non-current liabilities' 'Equity']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_5.loc[condition, 'class_name_2'] = data_5.loc[condition, 'name']\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:145: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_5['class_name_2'] = data_5['class_name_2'].fillna(method='ffill')\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  asserts_part['class_name_1'] = 'Assets'\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  liabilities_part['class_name_1'] = 'Liabilities and equity'\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:144: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Current assets' 'Non-current assets' 'Current liabilities'\n",
      " 'Non-current liabilities' 'Equity']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_5.loc[condition, 'class_name_2'] = data_5.loc[condition, 'name']\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:145: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_5['class_name_2'] = data_5['class_name_2'].fillna(method='ffill')\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[2.016672969299401 2.0178969876184776]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge.loc[condition, f'{col}_pct_diff'] = abs(data_merge.loc[condition,f'{col}_diff'] / data_merge.loc[condition,col_cols_list[0]])\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.0012024972408455727 0.0 0.7256310412587301 0.7277086060905392\n",
      " 0.016917200432805243 0.01814151279272876]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge.loc[condition, f'{col}_pct_diff'] = abs(data_merge.loc[condition,f'{col}_diff'] / data_merge.loc[condition,col_cols_list[0]])\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.18221922954036063 0.0006678188310432643 0.021723580165766938 0.0 0.0\n",
      " 0.015991273998789326 0.08857343616311583 10.952485291683152 0.0\n",
      " 0.018124765874719333]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge.loc[condition, f'{col}_pct_diff'] = abs(data_merge.loc[condition,f'{col}_diff'] / data_merge.loc[condition,col_cols_list[0]])\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:183: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data_4_merge = data_4_merge.fillna(0)\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:188: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data_5_merge = data_5_merge.fillna(0)\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[2.19256157e-01 0.00000000e+00 3.01026024e-02 1.18593730e-02\n",
      " 0.00000000e+00 1.90184604e-03 1.82034621e-01 0.00000000e+00\n",
      " 6.28431000e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.31726451e-01 9.52807563e-02 0.00000000e+00 0.00000000e+00\n",
      " 8.23308590e-02 1.45933013e+00 2.14087811e-02 1.27329228e-01\n",
      " 0.00000000e+00 1.09524853e+01 0.00000000e+00 7.02718129e-06\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge.loc[condition, f'{col}_pct_diff'] = abs(data_merge.loc[condition,f'{col}_diff'] / data_merge.loc[condition,col_cols_list[0]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 dec\\BRFTO FX Exposure Model 02.12.2024 - With Pnl & Tax Credit -New Model.xlsx\n",
      "3 dec\\BRFTO FX Exposure Model 03.12.2024 - With Pnl & Tax Credit -New Model.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  asserts_part['class_name_1'] = 'Assets'\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  liabilities_part['class_name_1'] = 'Liabilities and equity'\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:144: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Current assets' 'Non-current assets' 'Current liabilities'\n",
      " 'Non-current liabilities' 'Equity']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_5.loc[condition, 'class_name_2'] = data_5.loc[condition, 'name']\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:145: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_5['class_name_2'] = data_5['class_name_2'].fillna(method='ffill')\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  asserts_part['class_name_1'] = 'Assets'\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  liabilities_part['class_name_1'] = 'Liabilities and equity'\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:144: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Current assets' 'Non-current assets' 'Current liabilities'\n",
      " 'Non-current liabilities' 'Equity']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_5.loc[condition, 'class_name_2'] = data_5.loc[condition, 'name']\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:145: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_5['class_name_2'] = data_5['class_name_2'].fillna(method='ffill')\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.0904938863386568 0.08939889101759459]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge.loc[condition, f'{col}_pct_diff'] = abs(data_merge.loc[condition,f'{col}_diff'] / data_merge.loc[condition,col_cols_list[0]])\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.10198977485231948 0.10090861994853964 0.09501216258582933\n",
      " 0.09392260702077927 0.002953670242047627 0.0017532813171484043]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge.loc[condition, f'{col}_pct_diff'] = abs(data_merge.loc[condition,f'{col}_diff'] / data_merge.loc[condition,col_cols_list[0]])\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.045849049578666874 0.0030351394794510796 0.003113525980109541\n",
      " 0.057138923303793145 0.006498138021760057 0.0 0.0006825278201589199\n",
      " 0.013941330275450282 0.0116665670272447 0.0 0.006006235685195532\n",
      " 0.0017911538793142698]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge.loc[condition, f'{col}_pct_diff'] = abs(data_merge.loc[condition,f'{col}_diff'] / data_merge.loc[condition,col_cols_list[0]])\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:183: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data_4_merge = data_4_merge.fillna(0)\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.07135622 0.         0.        ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge.loc[condition, f'{col}_pct_diff'] = abs(data_merge.loc[condition,f'{col}_diff'] / data_merge.loc[condition,col_cols_list[0]])\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:188: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data_5_merge = data_5_merge.fillna(0)\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[7.82997677e-02 7.82362556e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 4.00484992e-03 4.00484992e-03 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.14525984e-02 1.14525984e-02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.34623043e-03\n",
      " 0.00000000e+00 1.31350738e-03 1.12726575e-16 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 8.94060736e-03 9.06198531e-01 8.20749215e-01\n",
      " 0.00000000e+00 1.81698975e-02 2.24237634e-02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.16665670e-02 1.16665670e-02 7.26945920e-06\n",
      " 7.26945920e-06 0.00000000e+00 0.00000000e+00 0.00000000e+00]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge.loc[condition, f'{col}_pct_diff'] = abs(data_merge.loc[condition,f'{col}_diff'] / data_merge.loc[condition,col_cols_list[0]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 dec\\BRSFT FX Exposure Model 02.12.2024 - With Pnl & Tax Credit.xlsx\n",
      "3 dec\\BRSFT FX Exposure Model 03.12.2024 - With Pnl & Tax Credit.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  asserts_part['class_name_1'] = 'Assets'\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  liabilities_part['class_name_1'] = 'Liabilities and equity'\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:144: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Current assets' 'Non-current assets' 'Current liabilities'\n",
      " 'Non-current liabilities' 'Equity']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_5.loc[condition, 'class_name_2'] = data_5.loc[condition, 'name']\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:145: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_5['class_name_2'] = data_5['class_name_2'].fillna(method='ffill')\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  asserts_part['class_name_1'] = 'Assets'\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  liabilities_part['class_name_1'] = 'Liabilities and equity'\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:144: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Current assets' 'Non-current assets' 'Current liabilities'\n",
      " 'Non-current liabilities' 'Equity']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_5.loc[condition, 'class_name_2'] = data_5.loc[condition, 'name']\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:145: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_5['class_name_2'] = data_5['class_name_2'].fillna(method='ffill')\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.08872900124164665 0.09003977105875674]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge.loc[condition, f'{col}_pct_diff'] = abs(data_merge.loc[condition,f'{col}_diff'] / data_merge.loc[condition,col_cols_list[0]])\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.0012024972408456005 0.0 0.0845089901786113 0.08581467933458063\n",
      " 0.0012024972408454903 0.0]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge.loc[condition, f'{col}_pct_diff'] = abs(data_merge.loc[condition,f'{col}_diff'] / data_merge.loc[condition,col_cols_list[0]])\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.14705624533082506 0.014793632053295947 0.048272494648014086 0.0\n",
      " 0.04533109608974957 0.028705809250831497 0.00026089070744219516\n",
      " 0.1388416726795731 0.04516637219905539 0.0]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge.loc[condition, f'{col}_pct_diff'] = abs(data_merge.loc[condition,f'{col}_diff'] / data_merge.loc[condition,col_cols_list[0]])\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:183: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data_4_merge = data_4_merge.fillna(0)\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\176471140.py:188: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data_5_merge = data_5_merge.fillna(0)\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_12256\\107726799.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[9.15047749e-01 9.15047749e-01 1.84900891e-02 3.82400837e-01\n",
      " 3.80215776e-01 2.77392315e-01 2.77392315e-01 0.00000000e+00\n",
      " 0.00000000e+00 4.92855609e-04 4.92855609e-04 3.53328289e-02\n",
      " 3.53328289e-02 1.51105155e-02 1.51105155e-02 3.48879343e-02\n",
      " 3.48879343e-02 0.00000000e+00 0.00000000e+00 1.45016556e-03\n",
      " 1.45016556e-03 8.75307750e-02 8.75307750e-02 4.26047729e-02\n",
      " 3.96149771e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.38841673e-01 1.38841673e-01 3.44142802e-05\n",
      " 3.44142802e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge.loc[condition, f'{col}_pct_diff'] = abs(data_merge.loc[condition,f'{col}_diff'] / data_merge.loc[condition,col_cols_list[0]])\n"
     ]
    }
   ],
   "source": [
    "if print_to_excel == True:\n",
    "    Output_file = f'{str(date.today())}_Brazil_monitoring_{month}.xlsx'\n",
    "    with pd.ExcelWriter(Output_file, engine='openpyxl', mode='w') as writer:\n",
    "        files_df_couple.to_excel(writer, index=False, sheet_name='all_files')\n",
    "\n",
    "list_to_del = [np.nan, '0', 0]\n",
    "for string_id in files_df_couple.index:\n",
    "    # try:\n",
    "    # read old data\n",
    "    old_path = f'{files_df_couple.loc[string_id, \"folder_old\"]}\\\\{files_df_couple.loc[string_id, \"files_old\"]}'\n",
    "    old_data = pd.read_excel(old_path, sheet_name=sheet_name)\n",
    "    old_data_date = files_df_couple.loc[string_id, \"day_old\"]\n",
    "    print(old_path)\n",
    "\n",
    "    # read new data\n",
    "    new_path = f'{files_df_couple.loc[string_id, \"folder_new\"]}\\\\{files_df_couple.loc[string_id, \"files_new\"]}'\n",
    "    new_data = pd.read_excel(new_path, sheet_name=sheet_name)\n",
    "    new_data_date = files_df_couple.loc[string_id, \"day_new\"]\n",
    "    print(new_path)\n",
    "\n",
    "    company_name = files_df_couple.loc[string_id, \"company\"]\n",
    "\n",
    "    count_data_date = 0\n",
    "    for data_date in [old_data, new_data]:\n",
    "        \n",
    "        count_data_date += 1\n",
    "\n",
    "\n",
    "\n",
    "        ### DATA_1\n",
    "        # 1)\tсначала видеть изменение общей позиции, суммарной день ко \n",
    "        # 2)\tзатем видеть изменение on-Balance и Off-Balance\n",
    "        start_str = 'USD Equivalent'\n",
    "        end_str = 'Net Exposure Balance BRL'\n",
    "\n",
    "        data_1 = data_date.loc[find_id_str(start_str):find_id_str(end_str),]\n",
    "        data_1 = del_null_data(data_1)\n",
    "        data_1 = data_1.iloc[:,:3].reset_index(drop=True)\n",
    "        data_1.columns = ['name'] + data_1.iloc[0,1:].values.tolist()\n",
    "\n",
    "        data_1 = data_1[~data_1.name.isna()]\n",
    "        data_1_melt = data_1.melt(id_vars='name', value_vars=data_1.columns.tolist()[1:],var_name='Exposure currency type', value_name='Value')\n",
    "        \n",
    "        data_11 = data_1_melt[data_1_melt.name.str.lower().str.contains('net')]\n",
    "        data_11.columns = ['Total net exposure'] + data_11.columns.tolist()[1:]\n",
    "        \n",
    "        data_12 = data_1_melt[~data_1_melt.name.str.lower().str.contains('net')]\n",
    "        data_12.columns = ['Total exposure split by Balance/Off balance'] + data_12.columns.tolist()[1:]\n",
    "\n",
    "        ### DATA_3\n",
    "        # 3)\tзатем видеть изменение итоговых балансовых статей:\n",
    "        start_str = 'USD denominated'\n",
    "        end_str = 'Total assets'\n",
    "        data_3 = data_date.loc[[find_id_str(start_str),find_id_str(end_str)],]\n",
    "        data_3 = del_null_data(data_3)\n",
    "\n",
    "        data_3 = data_to_parts(data_3)\n",
    "\n",
    "        col_1_name_data_3 = 'Total balance and off-balance items'\n",
    "\n",
    "        data_3_tr = data_3.transpose()\n",
    "        # rename cols and drop col name string\n",
    "        data_3_tr.columns = data_3_tr.iloc[0,:]\n",
    "        data_3_tr = data_3_tr.iloc[1:,:]\n",
    "        data_3_tr['name'] = data_3_tr.index\n",
    "        data_3_tr = data_3_tr.reset_index(drop=True)\n",
    "        # to parts\n",
    "        assets_col = [x for x in data_3_tr.columns.tolist() if 'assets' in x][0]\n",
    "        liabilities_col = [x for x in data_3_tr.columns.tolist() if 'liabilities' in x][0]\n",
    "\n",
    "\n",
    "        assets_data = data_3_tr[['name',assets_col]]\n",
    "        assets_data.columns = [col_1_name_data_3, 'Value']\n",
    "        assets_data['Balance item class'] = 'Assets'\n",
    "        liabilities_data = data_3_tr[['name',liabilities_col]]\n",
    "        liabilities_data.columns = [col_1_name_data_3, 'Value']\n",
    "        liabilities_data['Balance item class'] = 'Liabilities and equity'\n",
    "\n",
    "        data_3_tr = pd.concat([assets_data,liabilities_data], axis=0)\n",
    "        data_3_tr = data_3_tr.iloc[:,[2,0,1]]\n",
    "\n",
    "        data_3 = data_3_tr\n",
    "\n",
    "        ### DATA_4\n",
    "        # 4)\tзатем видеть изменения внебалансовых статей (их немного)\n",
    "        start_str = 'Total assets'\n",
    "        end_str = 'Total Off Balance Assets'\n",
    "        pre_data_4 = data_date.loc[find_id_str(start_str):find_id_str(end_str),]\n",
    "\n",
    "        start_str = 'Assets'\n",
    "        header_str = 'USD denominated'\n",
    "        start_id = pre_data_4.loc[pre_data_4['Unnamed: 1']=='Assets',:].index.item()\n",
    "        data_4 = pre_data_4.loc[start_id:]\n",
    "\n",
    "        header_df = data_date.loc[find_id_str(header_str):find_id_str(header_str)+1,]\n",
    "        data_4 = pd.concat([header_df,data_4],axis=0)\n",
    "        data_4 = del_null_data(data_4)\n",
    "\n",
    "        data_4 = data_to_parts(data_4, True)\n",
    "\n",
    "        data_4 = data_4[~data_4.iloc[:,0].isna()].reset_index(drop=True)\n",
    "        # del empty cols\n",
    "        cols_list = (~data_4.isin(list_to_del)).any(axis=0)\n",
    "        cols_list = cols_list[cols_list==True].index.tolist()\n",
    "        data_4 = data_4[cols_list]\n",
    "\n",
    "        data_4 = data_4[['class_name_1'] + data_4.columns.tolist()[:-1]]\n",
    "\n",
    "        # del string\n",
    "        str_to_find = 'Industrialization'\n",
    "        str_to_find = str_to_find.strip().lower()\n",
    "        data_4 = data_4[~data_4.name.str.lower().str.contains(str_to_find)]\n",
    "\n",
    "        # total to previous part\n",
    "        str_to_find = 'total'\n",
    "\n",
    "        data_to_3 = data_4[data_4.name.str.lower().str.contains(str_to_find)]\n",
    "        data_to_3 = data_to_3.iloc[:,:3]\n",
    "        data_to_3.columns = ['Balance item class', col_1_name_data_3, 'Value']\n",
    "        data_to_3.iloc[:,1] = 'Off balance'\n",
    "\n",
    "        data_3 = pd.concat([data_3,data_to_3],axis=0)\n",
    "\n",
    "        #final 4 part\n",
    "        data_4 = data_4[~data_4.name.str.lower().str.contains(str_to_find)]\n",
    "        data_4 = data_4.iloc[:, :3]\n",
    "        data_4.columns = ['Balance item class','Off- balance items','Value']\n",
    "\n",
    "        ### DATA_5\n",
    "        # 5)\tзатем видеть детальное изменение балансовых статей.\n",
    "        start_str = 'USD denominated'\n",
    "        end_str = 'Total assets'\n",
    "        data_5 = data_date.loc[find_id_str(start_str):find_id_str(end_str)-1,]\n",
    "        data_5 = del_null_data(data_5)\n",
    "\n",
    "        data_5 = data_to_parts(data_5, True)\n",
    "\n",
    "        data_5 = data_5[~data_5.iloc[:,0].isna()].reset_index(drop=True)\n",
    "\n",
    "        class_name_list = ['Current assets','Non-current assets','Current liabilities','Non-current liabilities','Equity']\n",
    "        class_name_list_lower = list(map(lambda x: x.strip().lower(), class_name_list))\n",
    "        data_5['class_name_2'] = np.nan\n",
    "        condition = data_5.name.str.strip().str.lower().isin(class_name_list_lower)\n",
    "        data_5.loc[condition, 'class_name_2'] = data_5.loc[condition, 'name']\n",
    "        data_5['class_name_2'] = data_5['class_name_2'].fillna(method='ffill')\n",
    "        data_5 = data_5[(data_5.name!=data_5.class_name_2)|(data_5.name=='Equity')].reset_index(drop=True)\n",
    "\n",
    "        data_5 = data_5[['class_name_1', 'class_name_2'] + data_5.columns.tolist()[:-2]]\n",
    "\n",
    "        data_5_melt = data_5.melt(id_vars=data_5.columns.tolist()[:3], value_vars=data_5.columns.tolist()[3:], value_name='Value', var_name='Exposure currency type')\n",
    "        data_5_melt = data_5_melt.iloc[:,1:]\n",
    "        data_5_melt.columns = ['Balance item class','Balance item name'] + data_5_melt.columns.tolist()[2:]\n",
    "        data_5 = data_5_melt\n",
    "        \n",
    "\n",
    "        if count_data_date == 1:\n",
    "            data_11_old = data_11\n",
    "            data_12_old = data_12\n",
    "            data_3_old = data_3\n",
    "            data_4_old = data_4\n",
    "            data_5_old = data_5\n",
    "        if count_data_date == 2:\n",
    "            data_11_new = data_11\n",
    "            data_12_new = data_12\n",
    "            data_3_new = data_3\n",
    "            data_4_new = data_4\n",
    "            data_5_new = data_5\n",
    "\n",
    "    # concat old and new data\n",
    "    ### data_1\n",
    "    data_11_merge = data_11_old.merge(data_11_new, how='outer', on=['Total net exposure','Exposure currency type'], suffixes=[f'_{old_data_date}',f'_{new_data_date}'])\n",
    "    data_11_merge = diff_by_cols(data_11_new,data_11_merge,2,False)\n",
    "\n",
    "    data_12_merge = data_12_old.merge(data_12_new, how='outer', on=['Total exposure split by Balance/Off balance','Exposure currency type'], suffixes=[f'_{old_data_date}',f'_{new_data_date}'])\n",
    "    data_12_merge = diff_by_cols(data_12_new,data_12_merge,2,False)\n",
    "\n",
    "    ### data_3\n",
    "    data_3_merge = data_3_old.merge(data_3_new, how='outer', on=['Balance item class','Total balance and off-balance items'], suffixes=[f'_{old_data_date}',f'_{new_data_date}'])\n",
    "    data_3_merge = diff_by_cols(data_3,data_3_merge, data_for_cols=False)\n",
    "\n",
    "    ### data_4\n",
    "    data_4_merge = data_4_old.merge(data_4_new, how='outer', on=['Balance item class','Off- balance items'], suffixes=[f'_{old_data_date}',f'_{new_data_date}'])\n",
    "    data_4_merge = data_4_merge.fillna(0)\n",
    "    data_4_merge = diff_by_cols(data_4,data_4_merge,2,data_for_cols=False)\n",
    "\n",
    "    ### data_5\n",
    "    data_5_merge = data_5_old.merge(data_5_new, how='outer', on=['Balance item class','Balance item name','Exposure currency type'], suffixes=[f'_{old_data_date}',f'_{new_data_date}'])\n",
    "    data_5_merge = data_5_merge.fillna(0)\n",
    "    data_5_merge = diff_by_cols(data_5,data_5_merge,3,data_for_cols=False)\n",
    "\n",
    "    ### TO EXCEL\n",
    "    if print_to_excel == True:\n",
    "        with pd.ExcelWriter(Output_file, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "            count_row = 0\n",
    "            pd.DataFrame({'company':company_name},index=[0]).to_excel(writer, startcol=2, header=False, index=False, sheet_name=company_name, startrow=count_row)\n",
    "            count_row += 2\n",
    "            files_df_couple.loc[string_id:string_id,:].to_excel(writer, startcol=2, header=True, index=False, sheet_name=company_name, startrow=count_row)\n",
    "            count_row += 3\n",
    "            data_11_merge.to_excel(writer, startcol=2, header=True, index=False, sheet_name=company_name, startrow=count_row)\n",
    "            count_row += len(data_11_merge) + 2\n",
    "            data_12_merge.to_excel(writer, startcol=2, header=True, index=False, sheet_name=company_name, startrow=count_row)\n",
    "            count_row += len(data_12_merge) + 2\n",
    "            data_3_merge.to_excel(writer, startcol=2, header=True, index=False, sheet_name=company_name, startrow=count_row)\n",
    "            count_row += len(data_3_merge) + 2\n",
    "            data_4_merge.to_excel(writer, startcol=2, header=True, index=False, sheet_name=company_name, startrow=count_row)\n",
    "            count_row += len(data_4_merge) + 2\n",
    "            data_5_merge.to_excel(writer, startcol=2, header=True, index=False, sheet_name=company_name, startrow=count_row)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     print(e, 'in string ',string_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BRFHRG ', 'BRFTO ', 'BRSFT ']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_df_couple.company.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FORMAT\n",
    "if print_to_excel == True:\n",
    "    \n",
    "    for company_name in files_df_couple.company.unique().tolist():\n",
    "        \n",
    "        # open file\n",
    "        wb = openpyxl.load_workbook(Output_file)\n",
    "        ws = wb[company_name]\n",
    "\n",
    "        # Weight of olumns\n",
    "        ws.column_dimensions['A'].width = 4\n",
    "        ws.column_dimensions['B'].width = 4\n",
    "        ws.column_dimensions['C'].width = 37\n",
    "        ws.column_dimensions['D'].width = 41\n",
    "        ws.column_dimensions['E'].width = 25\n",
    "        ws.column_dimensions['F'].width = 16\n",
    "        ws.column_dimensions['G'].width = 16\n",
    "        ws.column_dimensions['H'].width = 16\n",
    "        ws.column_dimensions['I'].width = 16\n",
    "\n",
    "        #alignment \n",
    "        from openpyxl.styles import Alignment\n",
    "        for row in ws['C1:I200']:\n",
    "            for cell in row:\n",
    "                cell.alignment = Alignment(horizontal='left')\n",
    "        for row in ws['E6:I200']:\n",
    "            for cell in row:\n",
    "                cell.alignment = Alignment(horizontal='right')\n",
    "                cell.number_format = '# ### ###.00'\n",
    "\n",
    "        # close file\n",
    "        wb.save(Output_file)\n",
    "        wb.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
