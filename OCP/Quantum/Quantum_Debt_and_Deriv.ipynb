{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Today = '30/06/24'\n",
    "# Today_1 and TODAY_2!!!\n",
    "\n",
    "Mounth = 'Jun'\n",
    "\n",
    "print_Debt = True\n",
    "print_Deriv = True\n",
    "print_BD = False\n",
    "excel_tofolder_on_Z = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\KlimovaAnnaA\\\\Documents\\\\MyFiles\\\\Projects\\\\OCP\")\n",
    "from Defs import merge_SalesUnits\n",
    "from Defs import merge_Mapping\n",
    "from Defs import Period\n",
    "from Defs import new_list\n",
    "from Defs import export_from_RISKCUSTOM\n",
    "from Defs import add_in_currency_column\n",
    "from Defs import concat_columns\n",
    "from Defs import export_from_WHWEEK\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:93: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(102706, 73)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"select * from \"RISKACCESS\".\"quantumDebt\" where \"reportDate\" = TO_DATE('{Today}', 'DD/MM/YY')\"\"\"\n",
    "data_Debt_export = export_from_RISKCUSTOM(query)\n",
    "data_Debt_export.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6855, 73)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Debt_export.holding.unique()\n",
    "max_data = data_Debt_export.effectiveFrom.max()\n",
    "data_Debt_export.query('effectiveFrom == @max_data').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтрация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:93: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:38: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['SGC' 'SGC' 'SGC' ... 'SUEK RU' 'SUEK RU' 'SPV']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merge_data.loc[merge_data[f'{id_col}_merge'] != 'External', 'last_merge'] = merge_data.loc[merge_data[f'{id_col}_merge'] != 'External', f'{id_col}_merge']\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_3232\\2281321293.py:43: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  data_Debt_work.loc[data_Debt_work.counterparty.str.contains('(EC)'), 'counterparty'] = data_Debt_work.loc[data_Debt_work.counterparty.str.contains('(EC)'), 'counterparty'].str[:-5]\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:93: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:38: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merge_data.loc[merge_data[f'{id_col}_merge'] != 'External', 'last_merge'] = merge_data.loc[merge_data[f'{id_col}_merge'] != 'External', f'{id_col}_merge']\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:93: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:38: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['SAMSALES' 'SAMSALES' 'SAMSALES' ... 'RUFERT' 'RUFERT' 'RUFERT']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merge_data.loc[merge_data[f'{id_col}_merge'] != 'External', 'last_merge'] = merge_data.loc[merge_data[f'{id_col}_merge'] != 'External', f'{id_col}_merge']\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_3232\\2281321293.py:43: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  data_Debt_work.loc[data_Debt_work.counterparty.str.contains('(EC)'), 'counterparty'] = data_Debt_work.loc[data_Debt_work.counterparty.str.contains('(EC)'), 'counterparty'].str[:-5]\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:93: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:38: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'SAMSALES'\n",
      " 'SAMSALES' 'EURSALES' 'EURSALES' 'EURSALES' 'RUFERT' 'TRADING' 'NAMSALES'\n",
      " 'SAMSALES' 'SAMSALES' 'SAMSALES' 'SPV' 'SPV' 'SPV' 'RUFERT' 'RUFERT'\n",
      " 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'SPV'\n",
      " 'SPV' 'NAMSALES' 'NAMSALES' 'EURSALES' 'EURSALES']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merge_data.loc[merge_data[f'{id_col}_merge'] != 'External', 'last_merge'] = merge_data.loc[merge_data[f'{id_col}_merge'] != 'External', f'{id_col}_merge']\n"
     ]
    }
   ],
   "source": [
    "max_data = data_Debt_export.effectiveFrom.max() # Присваивание переменной значения мин даты в столбце effectiveFrom\n",
    "\n",
    "for i in ['SUEK', 'EuroChem']:\n",
    "    data_Debt_work = data_Debt_export.query('holding == @i & effectiveFrom == @max_data').reset_index(drop=True) # Фильтрация данных по столбцу holding (переменная Group) и effectiveFrom\n",
    "    data_Debt_work = data_Debt_work[~data_Debt_work.entity.isna()]\n",
    "    data_Debt_work.entity = data_Debt_work.entity.replace({'RUBND': 'RUSBO'}).reset_index(drop=True)\n",
    "    if i == 'SUEK':\n",
    "        data_Debt_work = data_Debt_work.rename(columns={'entity': 'pre_entity'})\n",
    "        data_Debt_work['entity'] = merge_Mapping(data_Debt_work, col='pre_entity')\n",
    "\n",
    "    data_Debt_work['Entity_group'] = merge_SalesUnits(data_Debt_work, col='entity', merge_col='ocpSegment').fillna('External')\n",
    "\n",
    "    # Выполнение цикла для рассчета amount, amountUSD и присваивания значения counterparty для каждого DealSet\n",
    "\n",
    "    deals_data = data_Debt_work[['entity', 'Entity_group', 'counterparty','amount', 'amountUSD', 'instrumentOwner', 'dealSet']] # Выбор нужного разреза данных\n",
    "    deals_data_Bonds = deals_data[deals_data.dealSet.str.contains('Bond')] # Фильтрация разреза по значениям в DealSet, которые содержат слово Bond\n",
    "\n",
    "    Bonds_list = deals_data_Bonds.dealSet.unique()\n",
    "\n",
    "    for Bond in Bonds_list:\n",
    "        try:\n",
    "            Bond_data = deals_data_Bonds.query('dealSet ==@Bond') # Отбор данных одного Bond\n",
    "            assert len(Bond_data[Bond_data.instrumentOwner == 'EC_ISSUED_BONDS']) != 0\n",
    "\n",
    "            for column in Bond_data[['amount', 'amountUSD']]:\n",
    "                Traded_data_sum = Bond_data.query('instrumentOwner ==\"EC_TRADED_BONDS\"')[column].sum()\n",
    "                Issued_data = Bond_data.query('instrumentOwner ==\"EC_ISSUED_BONDS\"')[column]\n",
    "                # Внесение нового значения amount в issued bonds\n",
    "                Bond_data.loc[Bond_data['instrumentOwner'] ==\"EC_ISSUED_BONDS\", column] = Traded_data_sum + Issued_data \n",
    "            # Внесение нового значения counterparty в traded bonds\n",
    "            Issied_data_entity = Bond_data.query('instrumentOwner ==\"EC_ISSUED_BONDS\"').Entity.squeeze()\n",
    "            Bond_data.loc[Bond_data['instrumentOwner'] ==\"EC_TRADED_BONDS\", 'counterparty'] = Issied_data_entity\n",
    "            deals_data_Bonds.loc[deals_data_Bonds['dealSet'] == Bond] = Bond_data\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    deals_data.loc[deals_data.dealSet.str.contains('Bond')] = deals_data_Bonds\n",
    "    data_Debt_work[['entity', 'Entity_group', 'counterparty','amount', 'amountUSD', 'instrumentOwner', 'dealSet']] = deals_data\n",
    "    # Запись выполненного цикла в в основные данные\n",
    "\n",
    "    data_Debt_work = Period(data_Debt_work, day_for_count=Today, col_with_date='actionDate').reset_index(drop=True)\n",
    "\n",
    "    data_Debt_work.loc[data_Debt_work.counterparty.str.contains('(EC)'), 'counterparty'] = data_Debt_work.loc[data_Debt_work.counterparty.str.contains('(EC)'), 'counterparty'].str[:-5] \n",
    "    # Обрезка \" (EC)\" в каждой строке\n",
    "\n",
    "    data_Debt_work = data_Debt_work[~data_Debt_work.counterparty.isna()].reset_index(drop=True)\n",
    "    data_Debt_work['CompCode'] = merge_Mapping(data_Debt_work, col='counterparty').fillna('External')\n",
    "    data_Debt_work['Counterparty_Group'] = merge_SalesUnits(data_Debt_work, col='CompCode', merge_col='ocpSegment').fillna('External')\n",
    "    # Merge counterparty с Mapping и SalesUnits\n",
    "\n",
    "    data_Debt_work['Source'] = 'Quantum'\n",
    "\n",
    "    if i == 'SUEK':\n",
    "        data_Debt_work_SUEK = data_Debt_work\n",
    "    if i == 'EuroChem':\n",
    "        data_Debt_work_ECH = data_Debt_work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запись Debt в Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sheet_in_output_Debt = 'Debt'\n",
    "Output_Debt_SUEK = \"_\".join([str(date.today()), 'SUEK_quantum_Debt', f'{Mounth}.xlsx'])\n",
    "Output_Debt_ECH = \"_\".join([str(date.today()), 'Ech_quantum_Debt', f'{Mounth}.xlsx'])\n",
    "if excel_tofolder_on_Z == True:\n",
    "    Output_path = 'z:\\\\Anna_Klimova\\\\OCP\\\\Archive\\\\'\n",
    "    Output_Debt_SUEK = Output_path + Output_Debt_SUEK\n",
    "    Output_Debt_ECH = Output_path + Output_Debt_ECH\n",
    "\n",
    "data_Debt_export_for_print_SUEK = data_Debt_work_SUEK[['entity', 'Entity_group','counterparty',\\\n",
    "                                'Counterparty_Group','amount','eventCurrency','amountUSD','actionDate','Days',\\\n",
    "                                'Period','dealClass1','dealClass2','instrumentOwner','dealSet','facility','Source']]\\\n",
    "                                .rename(columns={'amount': 'amoutn outstanding',\\\n",
    "                                                    'eventCurrency': 'Currency',\\\n",
    "                                                    'amountUSD': 'amount USD eq',\\\n",
    "                                                    'actionDate': 'termEnd'})\n",
    "data_Debt_export_for_print_ECH = data_Debt_work_ECH[['entity', 'Entity_group','counterparty',\\\n",
    "                                'Counterparty_Group','amount','eventCurrency','amountUSD','actionDate','Days',\\\n",
    "                                'Period','dealClass1','dealClass2','instrumentOwner','dealSet','facility','Source']]\\\n",
    "                                .rename(columns={'amount': 'amoutn outstanding',\\\n",
    "                                                    'eventCurrency': 'Currency',\\\n",
    "                                                    'amountUSD': 'amount USD eq',\\\n",
    "                                                    'actionDate': 'termEnd'})\n",
    "\n",
    "if print_Debt == True:\n",
    "    data_Debt_export_for_print_SUEK.to_excel(Output_Debt_SUEK, sheet_name = Sheet_in_output_Debt, index = False)\n",
    "    data_Debt_export_for_print_ECH.to_excel(Output_Debt_ECH, sheet_name = Sheet_in_output_Debt, index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>Entity_group</th>\n",
       "      <th>counterparty</th>\n",
       "      <th>amount</th>\n",
       "      <th>amountUSD</th>\n",
       "      <th>instrumentOwner</th>\n",
       "      <th>dealSet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>KIT Finance Dealing</td>\n",
       "      <td>2100000.0</td>\n",
       "      <td>2100000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>KIT Finance Dealing</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>KIT Finance Dealing</td>\n",
       "      <td>1125000.0</td>\n",
       "      <td>1125000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>KIT Finance Dealing</td>\n",
       "      <td>1900000.0</td>\n",
       "      <td>1900000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>KIT Finance Dealing</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>KIT Finance Dealing</td>\n",
       "      <td>7750000.0</td>\n",
       "      <td>7750000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>KIT Finance Dealing</td>\n",
       "      <td>939000.0</td>\n",
       "      <td>939000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>KIT Finance Dealing</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>GENERIC EXTERNAL</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>KIT Finance Dealing</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>KIT Finance Dealing</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>KIT Finance Dealing</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>KIT Finance Dealing</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>KIT Finance Dealing</td>\n",
       "      <td>1986000.0</td>\n",
       "      <td>1986000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>KIT Finance Dealing</td>\n",
       "      <td>3700000.0</td>\n",
       "      <td>3700000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>KIT Finance Dealing</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>GENERIC EXTERNAL</td>\n",
       "      <td>1298000.0</td>\n",
       "      <td>1298000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>GENERIC EXTERNAL</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>GENERIC EXTERNAL</td>\n",
       "      <td>1255000.0</td>\n",
       "      <td>1255000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>MTS Bank RU</td>\n",
       "      <td>3100000.0</td>\n",
       "      <td>3100000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>NCC RU</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>NCC RU</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>EC_TRADED_BONDS</td>\n",
       "      <td>SUEK EuBond 2021 $500m B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entity Entity_group         counterparty      amount   amountUSD  \\\n",
       "8   RUEMO       RUFERT  KIT Finance Dealing   2100000.0   2100000.0   \n",
       "9   RUEMO       RUFERT  KIT Finance Dealing   1000000.0   1000000.0   \n",
       "10  RUEMO       RUFERT  KIT Finance Dealing   1125000.0   1125000.0   \n",
       "11  RUEMO       RUFERT  KIT Finance Dealing   1900000.0   1900000.0   \n",
       "12  RUEMO       RUFERT  KIT Finance Dealing    200000.0    200000.0   \n",
       "13  RUEMO       RUFERT  KIT Finance Dealing   7750000.0   7750000.0   \n",
       "14  RUEMO       RUFERT  KIT Finance Dealing    939000.0    939000.0   \n",
       "15  RUEMO       RUFERT  KIT Finance Dealing    200000.0    200000.0   \n",
       "16  RUEMO       RUFERT     GENERIC EXTERNAL    200000.0    200000.0   \n",
       "17  RUEMO       RUFERT  KIT Finance Dealing    200000.0    200000.0   \n",
       "18  RUEMO       RUFERT  KIT Finance Dealing    100000.0    100000.0   \n",
       "19  RUEMO       RUFERT  KIT Finance Dealing    800000.0    800000.0   \n",
       "20  RUEMO       RUFERT  KIT Finance Dealing   5000000.0   5000000.0   \n",
       "21  RUEMO       RUFERT  KIT Finance Dealing   1986000.0   1986000.0   \n",
       "22  RUEMO       RUFERT  KIT Finance Dealing   3700000.0   3700000.0   \n",
       "23  RUEMO       RUFERT  KIT Finance Dealing  10000000.0  10000000.0   \n",
       "24  RUEMO       RUFERT     GENERIC EXTERNAL   1298000.0   1298000.0   \n",
       "25  RUEMO       RUFERT     GENERIC EXTERNAL    300000.0    300000.0   \n",
       "26  RUEMO       RUFERT     GENERIC EXTERNAL   1255000.0   1255000.0   \n",
       "27  RUEMO       RUFERT          MTS Bank RU   3100000.0   3100000.0   \n",
       "28  RUEMO       RUFERT               NCC RU    250000.0    250000.0   \n",
       "29  RUEMO       RUFERT               NCC RU    200000.0    200000.0   \n",
       "\n",
       "    instrumentOwner                   dealSet  \n",
       "8   EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "9   EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "10  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "11  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "12  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "13  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "14  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "15  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "16  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "17  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "18  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "19  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "20  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "21  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "22  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "23  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "24  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "25  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "26  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "27  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "28  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  \n",
       "29  EC_TRADED_BONDS  SUEK EuBond 2021 $500m B  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = data_Debt_work[['entity', 'Entity_group', 'counterparty','amount', 'amountUSD', 'instrumentOwner', 'dealSet']]\n",
    "check = check[check.instrumentOwner.str.contains('BONDS')].reset_index(drop=True)\n",
    "check[check.dealSet == check.dealSet.unique().tolist()[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counterparty</th>\n",
       "      <th>CompCode</th>\n",
       "      <th>Counterparty_Group</th>\n",
       "      <th>entity</th>\n",
       "      <th>Entity_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Corrigo</td>\n",
       "      <td>External</td>\n",
       "      <td>External</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    counterparty  CompCode Counterparty_Group entity Entity_group\n",
       "400      Corrigo  External           External    NaN          NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_map = data_Debt_work.loc[(data_Debt_work['cpartyType'] == 'Internal') & (data_Debt_work['CompCode'] == 'External'), ['counterparty', 'CompCode', 'Counterparty_Group']].drop_duplicates()\n",
    "manual_map\n",
    "\n",
    "manual_map2 = data_Debt_work.loc[data_Debt_work['Entity_group'] == 'External', ['entity', 'Entity_group']].drop_duplicates()\n",
    "manual_map2\n",
    "\n",
    "manual_map_print = pd.concat([manual_map, manual_map2], axis=1)\n",
    "manual_map_print\n",
    "# manual_map_print.to_excel('Manual_map.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работа с Forwards и Swaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:93: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((15, 80), (18, 84))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = f\"\"\"select * from \"RISKACCESS\".\"quantumForwards\" \"\"\"\n",
    "# data_Forwards_export = export_from_RISKCUSTOM(query)\n",
    "# data_Forwards_export[data_Forwards_export.positionDate > '2024-03-01'].positionDate.unique()\n",
    "Today_1 = '2024-06-30'\n",
    "query = f\"\"\"select * from \"RISKACCESS\".\"quantumForwards\" where \"positionDate\" = TO_DATE('{Today_1}', 'YYYY-MM-DD')\"\"\"\n",
    "data_Forwards_export = export_from_RISKCUSTOM(query)\n",
    "\n",
    "# query = f\"\"\"select * from \"RISKACCESS\".\"quantumSwaps\" \"\"\"\n",
    "# data_Swaps_export = export_from_RISKCUSTOM(query)\n",
    "# data_Swaps_export[data_Swaps_export.positionDate > '2024-03-01'].positionDate.unique(\n",
    "Today_2 = '30/06/24'\n",
    "query = f\"\"\"select * from \"RISKACCESS\".\"quantumSwaps\" where \"positionDate\" = TO_DATE('{Today_2}', 'DD/MM/YY')\"\"\"\n",
    "data_Swaps_export = export_from_RISKCUSTOM(query)\n",
    "\n",
    "data_Forwards_export.shape, data_Swaps_export.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_3232\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_3232\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_3232\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_3232\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_3232\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_3232\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_3232\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_3232\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_3232\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_3232\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_3232\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_3232\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_3232\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_3232\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_3232\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:93: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:160: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[f'Coef_to_{CCY_to}'] = df.date_CCY_from.replace(coef_dict).fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_Swaps_export is empty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:93: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:38: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES'\n",
      " 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES'\n",
      " 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES'\n",
      " 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES'\n",
      " 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'SAMSALES' 'SAMSALES']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merge_data.loc[merge_data[f'{id_col}_merge'] != 'External', 'last_merge'] = merge_data.loc[merge_data[f'{id_col}_merge'] != 'External', f'{id_col}_merge']\n"
     ]
    }
   ],
   "source": [
    "data_work_list = [data_Forwards_export, data_Swaps_export]\n",
    "\n",
    "for data_Deriv_index in range(len(data_work_list)):\n",
    "    # Проверка вхождений dealNo в Debt и остановка процесса в случае отсутвия данных:\n",
    "    data_Deriv = data_work_list[data_Deriv_index]\n",
    "    dealNo_intersect_list = list(set(data_Deriv['dealNo']).intersection(set(data_Debt_export['dealNo'])))\n",
    "    data_work_Deriv = data_Deriv[~(data_Deriv.dealNo.isin(dealNo_intersect_list))]\n",
    "    if len(data_work_Deriv) == 0:\n",
    "        if data_Deriv_index == 0:\n",
    "            print('data_Forwards_export is empty')\n",
    "            data_print_Forwards = pd.DataFrame()\n",
    "            continue\n",
    "        else:\n",
    "            print('data_Swaps_export is empty')\n",
    "            data_print_Swaps = pd.DataFrame()\n",
    "            continue\n",
    "        \n",
    "    data_work_Deriv['holdingEntity'] = data_work_Deriv['holdingEntity'].replace({'XXTSU': 'SUEK'})\n",
    "\n",
    "    # Создание входящей пары внизу\n",
    "    Data_for_loop = data_work_Deriv[['entity','holdingEntity','counterparty','dealNo', 'payFaceValue', 'payFXCurrency', 'recFaceValue', 'recFXCurrency', 'maturityDate']]\n",
    "    for i in range(0, len(Data_for_loop)):\n",
    "        row_list = list(Data_for_loop.loc[i])\n",
    "        Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
    "        Data_for_loop.loc[i,'payFaceValue'] = Data_for_loop.loc[i,'payFaceValue'] * -1\n",
    "    Data_for_loop = Data_for_loop.sort_values('dealNo')\n",
    "    # цикл создания новых строк\n",
    "    Data_for_loop = Period(Data_for_loop, day_for_count=Today_1, col_with_date='maturityDate')\n",
    "    # Создание Days и Period\n",
    "    Data_for_loop = add_in_currency_column(Data_for_loop, CCY_to='USD', col_with_CCY='payFXCurrency', date_is_column=False, col_with_VAL='payFaceValue', DATE=Today_1)\n",
    "    # создание payFaceValue_in_USD\n",
    "    new_columns = ['Company', 'Settlement', 'Notional_Amount_(USD)', 'Unnamed', 'source']\n",
    "    Data_for_loop = Data_for_loop.reindex(columns=(Data_for_loop.columns.tolist() + new_columns))\n",
    "    Data_for_loop['source'] = 'Quantum'\n",
    "    # Создание пустых столбцов и столбца ресурса\n",
    "\n",
    "    if data_Deriv_index == 0:\n",
    "        data_print_Forwards = Data_for_loop\n",
    "    else:\n",
    "        data_print_Swaps = Data_for_loop\n",
    "\n",
    "data_print_Deriv = pd.concat([data_print_Forwards, data_print_Swaps], axis=0)\n",
    "# Объединение таблиц вниз\n",
    "\n",
    "data_print_Deriv_columns = {x:y for x,y in zip(data_print_Deriv.columns.tolist(), [[] for x in data_print_Deriv.columns.tolist()])}\n",
    "data_print_Deriv_columns['Entity_group']=[]\n",
    "data_print_Deriv_SUEK = pd.DataFrame(data_print_Deriv_columns)\n",
    "data_print_Deriv_Ech = pd.DataFrame(data_print_Deriv_columns)\n",
    "for i in ['SUEK', 'EuroChem']:\n",
    "    data_print_Deriv_group = data_print_Deriv[data_print_Deriv.holdingEntity == i].reset_index(drop=True)\n",
    "    if len(data_print_Deriv_group) == 0:\n",
    "        continue   \n",
    "    if i == 'SUEK':\n",
    "        data_print_Deriv_group = data_print_Deriv_group.rename(columns={'entity': 'pre_entity'})\n",
    "        data_print_Deriv_group['entity'] = merge_Mapping(Data_for_loop, col='pre_entity')\n",
    "        \n",
    "    data_print_Deriv_group['Entity_group'] = merge_SalesUnits(data_print_Deriv_group, col='entity', merge_col='ocpSegment').fillna('External')\n",
    "    data_print_Deriv_group = data_print_Deriv_group[['entity','Entity_group','holdingEntity','Company',\\\n",
    "        'counterparty','dealNo','payFXCurrency','payFaceValue',\\\n",
    "        'payFaceValue_in_USD','Settlement','Notional_Amount_(USD)',\\\n",
    "        'Unnamed','maturityDate','Days','Period','source']]\n",
    "    if i == 'SUEK':\n",
    "        data_print_Deriv_SUEK = data_print_Deriv_group\n",
    "    if i == 'EuroChem':\n",
    "        data_print_Deriv_Ech = data_print_Deriv_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запись Deriv в файл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sheet_in_output_Deriv = 'Deriv'\n",
    "Output_Deriv_SUEK = \"_\".join([str(date.today()), 'SUEK_quantum_Deriv', f'{Mounth}.xlsx'])\n",
    "Output_Deriv_Ech = \"_\".join([str(date.today()), 'Ech_quantum_Deriv', f'{Mounth}.xlsx'])\n",
    "if excel_tofolder_on_Z == True:\n",
    "    Output_path = 'z:\\\\Anna_Klimova\\\\OCP\\\\Archive\\\\'\n",
    "    Output_Deriv_SUEK = Output_path + Output_Deriv_SUEK\n",
    "    Output_Deriv_Ech = Output_path + Output_Deriv_Ech\n",
    "\n",
    "if print_Deriv == True:\n",
    "    if len(data_print_Deriv_SUEK) != 0:\n",
    "        data_print_Deriv_SUEK.to_excel(Output_Deriv_SUEK, sheet_name=Sheet_in_output_Deriv, index=False)\n",
    "    if len(data_print_Deriv_Ech) != 0:\n",
    "        data_print_Deriv_Ech.to_excel(Output_Deriv_Ech, sheet_name=Sheet_in_output_Deriv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Quantum\\Quantum_Debt_and_Deriv.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/KlimovaAnnaA/Documents/MyFiles/Projects/OCP/Quantum/Quantum_Debt_and_Deriv.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m2\u001b[39m\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 2==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сверка форвардов с новой бд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = f\"\"\"select * from \"RISKACCESS\".\"unifiedOcp\" \n",
    "# where \"reportDate\" = TO_DATE('{Today}', 'DD/MM/YY')\n",
    "# and \"sourceSystem\" = 'QUANTUM'\n",
    "# \"\"\"\n",
    "# data = export_from_RISKCUSTOM(query)\n",
    "# data_Der = data[data.accountType == 'Derivative']\n",
    "# unifiedOcp_dealNo_list = data_Der.recordId.unique().tolist()\n",
    "\n",
    "# query = f\"\"\"select * from \"RISKACCESS\".\"quantumForwards\" \"\"\"\n",
    "# data_Forwards_export = export_from_RISKCUSTOM(query)\n",
    "# data_list = data_Forwards_export[data_Forwards_export.positionDate > '2024-03-01'].positionDate.dt.date.astype(str).unique().tolist()\n",
    "\n",
    "# date_diff_dict = {}\n",
    "\n",
    "# for date_i in data_list:\n",
    "#     query = f\"\"\"select * from \"RISKACCESS\".\"quantumForwards\" where \"positionDate\" = TO_DATE('{date_i}', 'YYYY-MM-DD')\"\"\"\n",
    "#     data_Forwards_export = export_from_RISKCUSTOM(query)\n",
    "#     dealNo_intersect_list = list(set(data_Forwards_export['dealNo']).intersection(set(data_Debt_export['dealNo'])))\n",
    "#     data_work_Forwards = data_Forwards_export[~(data_Forwards_export.dealNo.isin(dealNo_intersect_list))]\n",
    "\n",
    "#     Forwars_dealNo_list = data_work_Forwards.dealNo.astype(str).unique().tolist()\n",
    "#     deal_No_intersect_list = [i for i in Forwars_dealNo_list if i in unifiedOcp_dealNo_list]\n",
    "#     diff_F_inter = len(Forwars_dealNo_list) - len(deal_No_intersect_list)\n",
    "#     diff_U_inter = len(unifiedOcp_dealNo_list) - len(deal_No_intersect_list)\n",
    "\n",
    "#     date_diff_dict[date_i] = {'diff_F': diff_F_inter, 'diff_U': diff_U_inter}\n",
    "\n",
    "# diff_df = pd.DataFrame(date_diff_dict).transpose()\n",
    "# diff_df[(diff_df.diff_F == diff_df.diff_F.min()) & (diff_df.diff_U == diff_df.diff_U.min())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = f\"\"\"select * from \"RISKACCESS\".\"quantumForwards\" where \"positionDate\" = TO_DATE('2024-04-03', 'YYYY-MM-DD')\"\"\"\n",
    "# data_Forwards_export = export_from_RISKCUSTOM(query)\n",
    "# dealNo_intersect_list = list(set(data_Forwards_export['dealNo']).intersection(set(data_Debt_export['dealNo'])))\n",
    "# data_work_Forwards = data_Forwards_export[~(data_Forwards_export.dealNo.isin(dealNo_intersect_list))]\n",
    "\n",
    "# data_Forwards_piece = data_work_Forwards[['dealNo', 'payFXCurrency', 'payFaceValue']].reset_index(drop=True)\n",
    "# data_Forwards_piece.dealNo = data_Forwards_piece.dealNo.astype(str)\n",
    "# data_Der_piece = data_Der[['recordId', 'effectiveCurrency', 'volumeEffectiveCurrency']].reset_index(drop=True)\n",
    "# data_merge = data_Der_piece.merge(data_Forwards_piece, how='outer', left_on='recordId', right_on='dealNo')\n",
    "# data_merge = data_merge[data_merge.effectiveCurrency == data_merge.payFXCurrency]\n",
    "# data_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестовая БД:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:89: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:21: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  data_work.loc[data_work.counterpartyName.str.contains('(EC)'), 'counterpartyName'] = data_work.loc[data_work.counterpartyName.str.contains('(EC)'), 'counterpartyName'].str[:-5] # Обрезка \" (EC)\" в каждой строке\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_merge_key_notna[f'{key}_is_equal'] = data_merge_key_notna[key] == data_merge_key_notna[col_dict[key]]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:67: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[False False False ... False False False]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge[(~data_merge[key].isna()) & (~data_merge[col_dict[key]].isna())] = data_merge_key_notna\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_merge_key_notna[f'{key}_is_equal'] = data_merge_key_notna[key] == data_merge_key_notna[col_dict[key]]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:67: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[ True  True  True ...  True  True  True]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge[(~data_merge[key].isna()) & (~data_merge[col_dict[key]].isna())] = data_merge_key_notna\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_merge_key_notna[f'{key}_is_equal'] = data_merge_key_notna[key] == data_merge_key_notna[col_dict[key]]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:67: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[ True  True  True ...  True  True  True]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge[(~data_merge[key].isna()) & (~data_merge[col_dict[key]].isna())] = data_merge_key_notna\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_merge_key_notna[f'{key}_is_equal'] = data_merge_key_notna[key] == data_merge_key_notna[col_dict[key]]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:67: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[ True  True  True ...  True  True  True]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge[(~data_merge[key].isna()) & (~data_merge[col_dict[key]].isna())] = data_merge_key_notna\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:21: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  data_work.loc[data_work.counterpartyName.str.contains('(EC)'), 'counterpartyName'] = data_work.loc[data_work.counterpartyName.str.contains('(EC)'), 'counterpartyName'].str[:-5] # Обрезка \" (EC)\" в каждой строке\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:40: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  data_der.loc[data_der.counterparty.str.contains('(EC)'), 'counterparty'] = data_der.loc[data_der.counterparty.str.contains('(EC)'), 'counterparty'].str[:-5] # Обрезка \" (EC)\" в каждой строке\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_der['CompCode'] = merge_Mapping(data_der, col='counterparty')\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:89: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merge_data.loc[merge_data[f'{id_col}_merge'] != 'External', 'last_merge'] = merge_data.loc[merge_data[f'{id_col}_merge'] != 'External', f'{id_col}_merge']\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_der['Counterparty_Group'] = merge_SalesUnits(data_der, col='CompCode', merge_col='ocpSegment')\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_merge_key_notna[f'{key}_is_equal'] = data_merge_key_notna[key] == data_merge_key_notna[col_dict[key]]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:67: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge[(~data_merge[key].isna()) & (~data_merge[col_dict[key]].isna())] = data_merge_key_notna\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_merge_key_notna[f'{key}_is_equal'] = data_merge_key_notna[key] == data_merge_key_notna[col_dict[key]]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:67: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge[(~data_merge[key].isna()) & (~data_merge[col_dict[key]].isna())] = data_merge_key_notna\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_merge_key_notna[f'{key}_is_equal'] = data_merge_key_notna[key] == data_merge_key_notna[col_dict[key]]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:67: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge[(~data_merge[key].isna()) & (~data_merge[col_dict[key]].isna())] = data_merge_key_notna\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_merge_key_notna[f'{key}_is_equal'] = data_merge_key_notna[key] == data_merge_key_notna[col_dict[key]]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15688\\1164580333.py:67: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_merge[(~data_merge[key].isna()) & (~data_merge[col_dict[key]].isna())] = data_merge_key_notna\n"
     ]
    }
   ],
   "source": [
    "# query = f\"\"\"\n",
    "# select * from \"unifiedOcp\"\n",
    "# where \"sourceSystem\" = 'QUANTUM'\n",
    "# and \"reportDate\" = TO_DATE('{Today}', 'DD/MM/YY')\n",
    "# \"\"\"\n",
    "# data = export_from_WHWEEK(query)\n",
    "\n",
    "query = f\"\"\"select * from \"RISKACCESS\".\"unifiedOcp\" \n",
    "where \"reportDate\" = TO_DATE('{Today}', 'DD/MM/YY')\n",
    "and \"sourceSystem\" = 'QUANTUM'\n",
    "\"\"\"\n",
    "data = export_from_RISKCUSTOM(query)\n",
    "\n",
    "group = 0\n",
    "data_list = [f'Слева-направо Вы ыидите выгрузку из QUANTUM и соответсвюущие ей строки из WHFLEX на {Today}', '']\n",
    "\n",
    "data.loc[data.holding.isna(),'holding'] = 'SUEK'\n",
    "for group in data.holding.unique().tolist():\n",
    "    data_work = data.loc[data.holding == group ,['##origin_name', 'holding', 'buCode', 'ocpSegment', 'counterpartyName', 'introgroupCounterpartyCode', 'counterpartySegment', 'effectiveCurrency', 'maturityDateFrom', 'volumeEffectiveCurrency']].reset_index(drop=True)\n",
    "\n",
    "    data_work.loc[data_work.counterpartyName.str.contains('(EC)'), 'counterpartyName'] = data_work.loc[data_work.counterpartyName.str.contains('(EC)'), 'counterpartyName'].str[:-5] # Обрезка \" (EC)\" в каждой строке\n",
    "\n",
    "    if group == 'SUEK':\n",
    "        data_work['CompCode'] = merge_Mapping(data_work, 'buCode')\n",
    "        data_work = data_work.rename(columns={'buCode': 'pre_buCode', 'CompCode':'buCode'})\n",
    "        \n",
    "        data_test = data_Debt_work_SUEK[['##origin_name', 'holding', 'entity', 'Entity_group', 'counterparty', 'CompCode', 'Counterparty_Group', 'eventCurrency','actionDate', 'amount']]\n",
    "        data_der = data_print_Deriv_SUEK[['source', 'holdingEntity', 'entity', 'Entity_group', 'counterparty', 'payFXCurrency', 'maturityDate', 'payFaceValue']]\n",
    "\n",
    "    if group == 'EUROCHEM':\n",
    "        data_test = data_Debt_work_ECH[['##origin_name', 'holding', 'entity', 'Entity_group', 'counterparty', 'CompCode', 'Counterparty_Group', 'eventCurrency','actionDate', 'amount']]\n",
    "        data_der = data_print_Deriv_Ech[['source', 'holdingEntity', 'entity', 'Entity_group', 'counterparty', 'payFXCurrency', 'maturityDate', 'payFaceValue']]\n",
    "\n",
    "    data_work = data_work.fillna('External')\n",
    "    data_work = data_work.groupby(['##origin_name', 'holding', 'buCode', 'ocpSegment', 'counterpartyName', 'introgroupCounterpartyCode', 'counterpartySegment', 'effectiveCurrency', 'maturityDateFrom'], as_index=False).agg({'volumeEffectiveCurrency': 'sum'})\n",
    "    data_work = concat_columns(df=data_work, columns=['buCode', 'counterpartyName', 'effectiveCurrency', 'maturityDateFrom']).reset_index(drop=True)\n",
    "\n",
    "    # Работа с деривативами \n",
    "    if len(data_der) != 0:\n",
    "        data_der.loc[data_der.counterparty.str.contains('(EC)'), 'counterparty'] = data_der.loc[data_der.counterparty.str.contains('(EC)'), 'counterparty'].str[:-5] # Обрезка \" (EC)\" в каждой строке\n",
    "        data_der['CompCode'] = merge_Mapping(data_der, col='counterparty')\n",
    "        data_der['Counterparty_Group'] = merge_SalesUnits(data_der, col='CompCode', merge_col='ocpSegment')\n",
    "        data_der = data_der.fillna('External')\n",
    "        data_der = data_der.rename(columns={'source':'##origin_name', 'holdingEntity':'holding', 'payFXCurrency':'eventCurrency', 'maturityDate':'actionDate', 'payFaceValue':'amount'})\n",
    "        # data_der = data_der.groupby(['##origin_name', 'holding', 'entity', 'Entity_group', 'counterparty', 'CompCode', 'Counterparty_Group', 'eventCurrency','actionDate'], as_index=False).agg({'amount': 'sum'})\n",
    "    else:\n",
    "        data_der = pd.DataFrame()\n",
    "    \n",
    "    data_test =  pd.concat([data_test, data_der], axis=0)\n",
    "    data_test = data_test.fillna('External')\n",
    "    data_test = data_test.groupby(['##origin_name', 'holding', 'entity', 'Entity_group', 'counterparty', 'CompCode', 'Counterparty_Group', 'eventCurrency','actionDate'], as_index=False).agg({'amount': 'sum'})\n",
    "    data_test = concat_columns(data_test, ['entity', 'counterparty', 'eventCurrency', 'actionDate']).reset_index(drop=True)\n",
    "\n",
    "    data_merge = data_test.merge(data_work, how='outer', left_on='concat_columns', right_on='concat_columns')\n",
    "    \n",
    "    # Сравнение величин \n",
    "    data_merge[['volumeEffectiveCurrency', 'amount']] = data_merge[['volumeEffectiveCurrency', 'amount']].fillna(0).astype('int64')\n",
    "    data_merge['Amount_is_equal'] = data_merge.amount.abs() == data_merge.volumeEffectiveCurrency.abs()\n",
    "\n",
    "    col_dict = {'Entity_group':'ocpSegment', 'CompCode':'introgroupCounterpartyCode', 'Counterparty_Group':'counterpartySegment', 'holding_x':'holding_y'}\n",
    "    data_merge.holding_y = data_merge.holding_y.replace({'EUROCHEM':'EuroChem'})\n",
    "\n",
    "    for key in list(col_dict.keys()):\n",
    "        data_merge[f'{key}_is_equal'] = np.NaN\n",
    "        data_merge_key_notna = data_merge[(~data_merge[key].isna()) & (~data_merge[col_dict[key]].isna())]\n",
    "        data_merge_key_notna[f'{key}_is_equal'] = data_merge_key_notna[key] == data_merge_key_notna[col_dict[key]]\n",
    "        data_merge[(~data_merge[key].isna()) & (~data_merge[col_dict[key]].isna())] = data_merge_key_notna\n",
    "\n",
    "    is_equal_cols_list = data_merge.columns[data_merge.columns.str.contains('is_equal')].tolist()\n",
    "    data_list.append(f'{group} points:')\n",
    "    for col in is_equal_cols_list:\n",
    "        if False in data_merge[col].unique().tolist():\n",
    "            data_list.append(f'{col}: ALARM')\n",
    "        else:\n",
    "            data_list.append(f'{col}: ok')\n",
    "    data_list.append('')\n",
    "\n",
    "    if group == 'SUEK':\n",
    "        data_merge_SUEK = data_merge\n",
    "    if group == 'EUROCHEM':\n",
    "        data_merge_Ech = data_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output_BD = \"_\".join([str(date.today()), 'QUANTUM_to_WHFLEX', f'{Mounth}.xlsx'])\n",
    "if print_BD == True:\n",
    "    write_data = {'data': data_list}\n",
    "    df = pd.DataFrame(write_data)\n",
    "    df.to_excel(Output_BD, sheet_name='Iinstruction', index=False, header=False)\n",
    "    \n",
    "    new_list(data_merge_SUEK, Output_BD, sheet_name='SUEK', index=True)\n",
    "    new_list(data_merge_Ech, Output_BD, sheet_name='Ech', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
