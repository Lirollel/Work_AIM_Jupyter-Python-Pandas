{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\KlimovaAnnaA\\\\Documents\\\\MyFiles\\\\Projects\\\\Working_attributes\")\n",
    "from Imports import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Today = '2024-09-30'\n",
    "\n",
    "print_Debt = True\n",
    "print_Deriv = False\n",
    "excel_tofolder_on_Z = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:92: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n"
     ]
    }
   ],
   "source": [
    "quantum_columns = str(export_from_RISKCUSTOM(\"\"\"select *from \"RISKACCESS\".\"quantumDebt\" fetch first 1 rows only\"\"\").columns.tolist()).replace('\\'','\\\"')[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7492, 74)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quantum debt\n",
    "query = f\"\"\"\n",
    "with table_1 as\n",
    "(select \n",
    "{quantum_columns},\n",
    "--\"reportDate\",\"effectiveFrom\",\"entity\",\"dealNo\",\"holding\",\"counterparty\",\"amount\",\"eventCurrency\",\"amountUSD\",\"actionDate\",\"dealClass1\",\"dealClass2\",\"instrumentOwner\",\"dealSet\",\"facility\", \n",
    "MAX(\"effectiveFrom\") OVER (partition BY \"reportDate\") as \"max_effectiveFrom\"\n",
    "from \"RISKACCESS\".\"quantumDebt\" \n",
    "where \"reportDate\" = TO_DATE('{Today}', 'YYYY-MM-DD')\n",
    "--fetch first 10 rows only\n",
    ")\n",
    "select * from table_1\n",
    "where \"effectiveFrom\" = table_1.\"max_effectiveFrom\"\n",
    "--fetch first 10 rows only\n",
    "\"\"\"\n",
    "data_Debt_export = export_from_RISKCUSTOM(query)\n",
    "data_Debt_export.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтрация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:92: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['SPV' 'SPV' 'SGC' ... 'SGC' 'SGC' 'SGC']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', 'last_merge'] = merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', f'{id_colmn}_merge']\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_10360\\1178440806.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Bond_data_issued['index_copy'] = Bond_data_issued.index # copy index\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_10360\\1178440806.py:53: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  data_Debt_work.loc[data_Debt_work.counterparty.str.contains('(EC)'), 'counterparty_name'] = data_Debt_work.loc[data_Debt_work.counterparty.str.contains('(EC)'), 'counterparty'].str[:-5]\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:92: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['EURSALES' 'EURSALES' 'NAMSALES' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT'\n",
      " 'RUFERT' 'RUFERT' 'RUFERT' 'SAMSALES' 'SAMSALES' 'SPV' 'SPV' 'SPV' 'SPV'\n",
      " 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT'\n",
      " 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT'\n",
      " 'EURSALES' 'EURSALES' 'EURSALES' 'NAMSALES' 'NAMSALES' 'SAMSALES'\n",
      " 'SAMSALES' 'EURSALES' 'SPV' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', 'last_merge'] = merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', f'{id_colmn}_merge']\n"
     ]
    }
   ],
   "source": [
    "assert len(data_Debt_export[data_Debt_export.entity.isna()]) == 0 # data quality\n",
    "data_Debt_work = data_Debt_export.copy() # copy data\n",
    "# merge\n",
    "data_Debt_work['entity_code'] = merge_Mapping(data_Debt_work, col='entity')\n",
    "data_Debt_work.loc[data_Debt_work.entity_code=='External', 'entity_code'] = data_Debt_work.loc[data_Debt_work.entity_code=='External', 'entity']\n",
    "data_Debt_work['Entity_group'] = merge_SalesUnits(data_Debt_work, col='entity_code', merge_col='ocpSegment')\n",
    "\n",
    "# Выполнение цикла для рассчета amount, amountUSD и присваивания значения counterparty для каждого DealSet\n",
    "\n",
    "# Выбор нужного разреза данных\n",
    "deals_data_Bonds = data_Debt_work.loc[data_Debt_work.dealSet.str.contains('Bond'), ['entity_code', 'Entity_group', 'counterparty','amount', 'amountUSD', 'instrumentOwner', 'dealSet','reportDate']] # Фильтрация разреза по значениям в DealSet, которые содержат слово Bond\n",
    "\n",
    "Bonds_list = deals_data_Bonds.dealSet.unique()\n",
    "\n",
    "deals_data_Bonds_work = pd.DataFrame()\n",
    "for Bond in Bonds_list:\n",
    "    try:\n",
    "        Bond_data = deals_data_Bonds[deals_data_Bonds.dealSet==Bond] # Отбор данных одного Bond\n",
    "        Bond_data_traded = Bond_data[Bond_data.instrumentOwner=='EC_TRADED_BONDS']\n",
    "        Bond_data_issued = Bond_data[Bond_data.instrumentOwner=='EC_ISSUED_BONDS']\n",
    "        if len(Bond_data_issued)>1:\n",
    "            Bond_data_issued['index_copy'] = Bond_data_issued.index # copy index\n",
    "            # groupby\n",
    "            Bond_data_issued_pivot = Bond_data_issued.groupby(as_index=False, dropna=False, by=['entity_code',\t'Entity_group',\t'counterparty', 'instrumentOwner',\t'dealSet',\t'reportDate']).agg({'amount':'sum', 'amountUSD':'sum', 'index_copy':'min'})\n",
    "            Bond_data_issued_pivot.index = [int(Bond_data_issued_pivot.index_copy.item())] # index on min in group\n",
    "            Bond_data_issued_pivot.drop(columns='index_copy') # drop index copy col\n",
    "            Bond_data = pd.concat([Bond_data_traded, Bond_data_issued_pivot])\n",
    "        assert len(Bond_data_issued) != 0\n",
    "\n",
    "        columns_list = ['amount', 'amountUSD']\n",
    "        for column in columns_list:\n",
    "            Traded_data_sum = float(Bond_data.loc[Bond_data.instrumentOwner=='EC_TRADED_BONDS', column].sum())\n",
    "            Issued_data = float(Bond_data.loc[Bond_data.instrumentOwner=='EC_ISSUED_BONDS', column].item())\n",
    "            # Внесение нового значения amount в issued bonds\n",
    "            Bond_data.loc[Bond_data['instrumentOwner'] ==\"EC_ISSUED_BONDS\", column] = Traded_data_sum + Issued_data \n",
    "        # Внесение нового значения counterparty в traded bonds\n",
    "        Issied_data_entity = Bond_data.loc[Bond_data.instrumentOwner=='EC_ISSUED_BONDS', 'entity_code'].squeeze()\n",
    "        Bond_data.loc[Bond_data['instrumentOwner'] ==\"EC_TRADED_BONDS\", 'counterparty'] = Issied_data_entity\n",
    "        \n",
    "        deals_data_Bonds_work = pd.concat([deals_data_Bonds_work, Bond_data])\n",
    "        # deals_data_Bonds[deals_data_Bonds.dealSet==Bond] = Bond_data\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "index_list = deals_data_Bonds_work.index.to_list()\n",
    "data_Debt_work.loc[(data_Debt_work.dealSet.str.contains('Bond'))&(data_Debt_work.index.isin(index_list)), ['entity_code', 'Entity_group', 'counterparty','amount', 'amountUSD', 'instrumentOwner', 'dealSet','reportDate']] = deals_data_Bonds_work\n",
    "data_Debt_work.loc[(data_Debt_work.dealSet.str.contains('Bond'))&(~data_Debt_work.index.isin(index_list)), 'entity_code'] = np.nan\n",
    "data_Debt_work = data_Debt_work[~data_Debt_work.entity_code.isna()]\n",
    "# Запись выполненного цикла в в основные данные\n",
    "\n",
    "data_Debt_work = Period(data_Debt_work, day_for_count='reportDate', col_with_date='actionDate', day_is_col=True).reset_index(drop=True)\n",
    "\n",
    "data_Debt_work.loc[data_Debt_work.counterparty.str.contains('(EC)'), 'counterparty_name'] = data_Debt_work.loc[data_Debt_work.counterparty.str.contains('(EC)'), 'counterparty'].str[:-5] \n",
    "# Обрезка \" (EC)\" в каждой строке\n",
    "\n",
    "assert len(data_Debt_export[data_Debt_export.counterparty.isna()])==0\n",
    "data_Debt_work['cty_Code'] = merge_Mapping(data_Debt_work, col='counterparty_name')\n",
    "data_Debt_work['Counterparty_Group'] = merge_SalesUnits(data_Debt_work, col='cty_Code', merge_col='ocpSegment')\n",
    "# Merge counterparty с Mapping и SalesUnits\n",
    "\n",
    "data_Debt_work['Source'] = 'Quantum'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запись Debt в Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "if print_Debt == True:\n",
    "    for holding in data_Debt_work.holding.unique().tolist():\n",
    "        Output_Debt = \"_\".join([str(date.today()), holding ,'quantum_Debt.xlsx'])\n",
    "        if excel_tofolder_on_Z == True:\n",
    "            Output_Debt = Output_path + Output_Debt\n",
    "        data_Debt_print = data_Debt_work.loc[data_Debt_work.holding==holding, ['entity_code', 'Entity_group','counterparty',\\\n",
    "                                    'Counterparty_Group','amount','eventCurrency','amountUSD','actionDate','Days',\\\n",
    "                                    'Period','dealClass1','dealClass2','instrumentOwner','dealSet','facility','Source']]\\\n",
    "                                    .rename(columns={'amount': 'amoutn outstanding',\\\n",
    "                                                        'eventCurrency': 'Currency',\\\n",
    "                                                        'amountUSD': 'amount USD eq',\\\n",
    "                                                        'actionDate': 'termEnd'})\n",
    "        data_Debt_print.to_excel(Output_Debt, sheet_name = 'Debt', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_code</th>\n",
       "      <th>Entity_group</th>\n",
       "      <th>counterparty</th>\n",
       "      <th>amount</th>\n",
       "      <th>amountUSD</th>\n",
       "      <th>instrumentOwner</th>\n",
       "      <th>dealSet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>NSD RU (EC)</td>\n",
       "      <td>-1.000000e+10</td>\n",
       "      <td>-1.078602e+08</td>\n",
       "      <td>EC_ISSUED_BONDS</td>\n",
       "      <td>MCC RuBond 07 2020-04 R10b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entity_code Entity_group counterparty        amount     amountUSD  \\\n",
       "16       RUEMO       RUFERT  NSD RU (EC) -1.000000e+10 -1.078602e+08   \n",
       "\n",
       "    instrumentOwner                     dealSet  \n",
       "16  EC_ISSUED_BONDS  MCC RuBond 07 2020-04 R10b  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = data_Debt_work[['entity_code', 'Entity_group', 'counterparty','amount', 'amountUSD', 'instrumentOwner', 'dealSet']]\n",
    "check = check[check.instrumentOwner.str.contains('BONDS')].reset_index(drop=True)\n",
    "check[check.dealSet == check.dealSet.unique().tolist()[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counterparty</th>\n",
       "      <th>entity_code</th>\n",
       "      <th>Counterparty_Group</th>\n",
       "      <th>entity_code</th>\n",
       "      <th>Entity_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [counterparty, entity_code, Counterparty_Group, entity_code, Entity_group]\n",
       "Index: []"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_map = data_Debt_work.loc[(data_Debt_work['cpartyType'] == 'Internal') & (data_Debt_work['entity_code'] == 'External'), ['counterparty', 'entity_code', 'Counterparty_Group']].drop_duplicates()\n",
    "manual_map\n",
    "\n",
    "manual_map2 = data_Debt_work.loc[data_Debt_work['Entity_group'] == 'External', ['entity_code', 'Entity_group']].drop_duplicates()\n",
    "manual_map2\n",
    "\n",
    "manual_map_print = pd.concat([manual_map, manual_map2], axis=1)\n",
    "manual_map_print\n",
    "# manual_map_print.to_excel('Manual_map.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работа с Forwards и Swaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:92: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_10360\\1716991512.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_Deriv_qu = pd.concat([data_Forwards_export,data_Swaps_export])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>##batch_id</th>\n",
       "      <th>##deleted</th>\n",
       "      <th>##inserted</th>\n",
       "      <th>##origin_name</th>\n",
       "      <th>adjustedProfitLoss</th>\n",
       "      <th>baseCurrency</th>\n",
       "      <th>baseType</th>\n",
       "      <th>checkSettlementDateAlt</th>\n",
       "      <th>contractRate</th>\n",
       "      <th>counterparty</th>\n",
       "      <th>...</th>\n",
       "      <th>recMargin</th>\n",
       "      <th>recPrincipalFreq</th>\n",
       "      <th>recRateBasisCode</th>\n",
       "      <th>recRateBasisFreq</th>\n",
       "      <th>recRateBasisName</th>\n",
       "      <th>recRateFormula</th>\n",
       "      <th>recRatesetFreq</th>\n",
       "      <th>shortInterestRate</th>\n",
       "      <th>shortNPVOfAdjustedProfitLoss</th>\n",
       "      <th>startdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41150557@WHPROD</td>\n",
       "      <td>N</td>\n",
       "      <td>2024-10-17 01:00:19</td>\n",
       "      <td>QUANTUM</td>\n",
       "      <td>2079.82</td>\n",
       "      <td>USD</td>\n",
       "      <td>CONTRACT</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.365100</td>\n",
       "      <td>Western Alliance US (EC)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41150557@WHPROD</td>\n",
       "      <td>N</td>\n",
       "      <td>2024-10-17 01:00:19</td>\n",
       "      <td>QUANTUM</td>\n",
       "      <td>1883.60</td>\n",
       "      <td>USD</td>\n",
       "      <td>CONTRACT</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.367691</td>\n",
       "      <td>Western Alliance US (EC)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ##batch_id ##deleted          ##inserted ##origin_name  \\\n",
       "0  41150557@WHPROD         N 2024-10-17 01:00:19       QUANTUM   \n",
       "1  41150557@WHPROD         N 2024-10-17 01:00:19       QUANTUM   \n",
       "\n",
       "   adjustedProfitLoss baseCurrency  baseType checkSettlementDateAlt  \\\n",
       "0             2079.82          USD  CONTRACT                      Y   \n",
       "1             1883.60          USD  CONTRACT                      Y   \n",
       "\n",
       "   contractRate              counterparty  ... recMargin recPrincipalFreq  \\\n",
       "0      1.365100  Western Alliance US (EC)  ...       NaN              NaN   \n",
       "1      1.367691  Western Alliance US (EC)  ...       NaN              NaN   \n",
       "\n",
       "  recRateBasisCode recRateBasisFreq recRateBasisName recRateFormula  \\\n",
       "0              NaN              NaN              NaN            NaN   \n",
       "1              NaN              NaN              NaN            NaN   \n",
       "\n",
       "  recRatesetFreq  shortInterestRate shortNPVOfAdjustedProfitLoss startdate  \n",
       "0            NaN                NaN                          NaN       NaT  \n",
       "1            NaN                NaN                          NaN       NaT  \n",
       "\n",
       "[2 rows x 106 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"select * \n",
    "from \"RISKACCESS\".\"quantumForwards\" \n",
    "where \"positionDate\" = TO_DATE('{Today}', 'YYYY-MM-DD')\"\"\"\n",
    "data_Forwards_export = export_from_RISKCUSTOM(query)\n",
    "\n",
    "query = f\"\"\"select * \n",
    "from \"RISKACCESS\".\"quantumSwaps\" \n",
    "where \"positionDate\" = TO_DATE('{Today}', 'YYYY-MM-DD')\"\"\"\n",
    "data_Swaps_export = export_from_RISKCUSTOM(query)\n",
    "\n",
    "data_Deriv_qu = pd.concat([data_Forwards_export,data_Swaps_export])\n",
    "data_Deriv_qu.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:92: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES'\n",
      " 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES'\n",
      " 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', 'last_merge'] = merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', f'{id_colmn}_merge']\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_10360\\1738275870.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_Deriv_qu_work['Entity_group'] = merge_SalesUnits(data_Deriv_qu_work, col='entity', merge_col='ocpSegment')\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:92: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:162: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[f'Coef_to_{CCY_to}'] = df.date_CCY_from.replace(coef_dict).fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# проверка вхождения в debt\n",
    "Deriv_dealNo = data_Deriv_qu.dealNo.unique().tolist()\n",
    "Debt_dealNo = data_Debt_export.dealNo.unique().tolist()\n",
    "Deriv_dealNo_new = [x for x in Deriv_dealNo if x not in Debt_dealNo]\n",
    "data_Deriv_qu_work = data_Deriv_qu[data_Deriv_qu.dealNo.isin(Deriv_dealNo_new)]\n",
    "# merge\n",
    "data_Deriv_qu_work['Entity_group'] = merge_SalesUnits(data_Deriv_qu_work, col='entity', merge_col='ocpSegment')\n",
    "# melt data\n",
    "melt_data = pd.melt(data_Deriv_qu_work, id_vars=['positionDate','holdingEntity','Entity_group','entity','counterparty','dealNo','payFaceValue','recFaceValue','maturityDate'], value_vars=['payFXCurrency','recFXCurrency'], value_name='Currency').sort_values('dealNo').rename(columns={'recFaceValue':'amount'})\n",
    "melt_data.loc[melt_data.variable=='payFXCurrency', 'amount'] = melt_data.loc[melt_data.variable=='payFXCurrency', 'payFaceValue'] * -1\n",
    "melt_data = melt_data.drop(columns=['payFaceValue','variable']).reset_index(drop=True).sort_values('dealNo')\n",
    "# Создание Days и Period\n",
    "melt_data = Period(melt_data, day_for_count=Today, col_with_date='maturityDate')\n",
    "# создание payFaceValue_in_USD\n",
    "melt_data = add_in_currency_column(melt_data, CCY_to='USD', col_with_CCY='Currency', date_is_column=False, col_with_VAL='amount', DATE=Today)\n",
    "# Создание пустых столбцов и столбца ресурса\n",
    "new_columns = ['Company', 'Settlement', 'Notional_Amount_(USD)', 'Unnamed', 'source']\n",
    "melt_data = melt_data.reindex(columns=(melt_data.columns.tolist() + new_columns))\n",
    "melt_data['source'] = 'Quantum'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запись Deriv в файл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if print_Deriv == True:\n",
    "    for holding in melt_data.holdingEntity.unique().tolist():\n",
    "        Output_Deriv = \"_\".join([str(date.today()), holding ,'quantum_Deriv.xlsx'])\n",
    "        if excel_tofolder_on_Z == True:\n",
    "            Output_Deriv = Output_path + Output_Deriv\n",
    "        \n",
    "        data_Deriv_print = melt_data.loc[melt_data.holdingEntity==holding,['entity','Entity_group','holdingEntity','Company',\\\n",
    "        'counterparty','dealNo','Currency','amount',\\\n",
    "        'amount_in_USD','Settlement','Notional_Amount_(USD)',\\\n",
    "        'Unnamed','maturityDate','Days','Period','source']]\n",
    "        data_Deriv_print.to_excel(Output_Deriv, sheet_name='Deriv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
