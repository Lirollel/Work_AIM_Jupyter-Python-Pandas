{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\KlimovaAnnaA\\\\Documents\\\\MyFiles\\\\Projects\\\\Working_attributes\")\n",
    "from Imports import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Today = '31/08/24'\n",
    "Today_1 = '2024-08-31'\n",
    "Today_2 = '31/08/24'\n",
    "# Today_1 and TODAY_2!!!\n",
    "\n",
    "print_Debt = True\n",
    "print_Deriv = True\n",
    "excel_tofolder_on_Z = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:88: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7340, 17)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "select * from \n",
    "(\n",
    "select \"reportDate\",\"effectiveFrom\",\"entity\",\"dealNo\",\"holding\",\"counterparty\",\"amount\",\"eventCurrency\",\"amountUSD\",\"actionDate\",\"dealClass1\",\"cpartyType\", \"dealClass2\",\"instrumentOwner\",\"dealSet\",\"facility\", \n",
    "MAX(\"effectiveFrom\") OVER (partition BY \"reportDate\") as \"max_effectiveFrom\"\n",
    "from \"RISKACCESS\".\"quantumDebt\" \n",
    "where \"reportDate\" = TO_DATE('{Today}', 'DD/MM/YY')\n",
    ")\n",
    "where \"effectiveFrom\" = \"max_effectiveFrom\"\n",
    "\"\"\"\n",
    "data_Debt_export = export_from_RISKCUSTOM(query)\n",
    "data_Debt_export.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтрация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:88: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['SGC' 'SGC' 'SGC' ... 'SGC' 'SGC' 'SGC']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', 'last_merge'] = merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', f'{id_colmn}_merge']\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_14832\\2192577195.py:41: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  data_Debt_work.loc[data_Debt_work.counterparty.str.contains('(EC)'), 'counterparty'] = data_Debt_work.loc[data_Debt_work.counterparty.str.contains('(EC)'), 'counterparty'].str[:-5]\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:88: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', 'last_merge'] = merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', f'{id_colmn}_merge']\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:88: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['RUFERT' 'RUFERT' 'RUFERT' ... 'SAMSALES' 'SAMSALES' 'SAMSALES']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', 'last_merge'] = merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', f'{id_colmn}_merge']\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_14832\\2192577195.py:41: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  data_Debt_work.loc[data_Debt_work.counterparty.str.contains('(EC)'), 'counterparty'] = data_Debt_work.loc[data_Debt_work.counterparty.str.contains('(EC)'), 'counterparty'].str[:-5]\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:88: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT'\n",
      " 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT' 'RUFERT'\n",
      " 'RUFERT' 'RUFERT' 'RUFERT' 'EURSALES' 'EURSALES' 'RUFERT' 'RUFERT'\n",
      " 'RUFERT' 'SAMSALES' 'SAMSALES' 'EURSALES' 'EURSALES' 'EURSALES'\n",
      " 'NAMSALES' 'NAMSALES' 'SPV' 'SAMSALES' 'SAMSALES' 'SAMSALES' 'SAMSALES'\n",
      " 'SPV' 'SPV' 'SPV' 'SPV' 'NAMSALES']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', 'last_merge'] = merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', f'{id_colmn}_merge']\n"
     ]
    }
   ],
   "source": [
    "for i in ['SUEK', 'EuroChem']:\n",
    "    data_Debt_work = data_Debt_export[data_Debt_export.holding==i].reset_index(drop=True) # Фильтрация данных по столбцу holding (переменная Group) и effectiveFrom\n",
    "    data_Debt_work = data_Debt_work[~data_Debt_work.entity.isna()]\n",
    "    data_Debt_work.entity = data_Debt_work.entity.replace({'RUBND': 'RUSBO'}).reset_index(drop=True)\n",
    "    if i == 'SUEK':\n",
    "        data_Debt_work = data_Debt_work.rename(columns={'entity': 'pre_entity'})\n",
    "        data_Debt_work['entity'] = merge_Mapping(data_Debt_work, col='pre_entity')\n",
    "\n",
    "    data_Debt_work['Entity_group'] = merge_SalesUnits(data_Debt_work, col='entity', merge_col='ocpSegment').fillna('External')\n",
    "\n",
    "    # Выполнение цикла для рассчета amount, amountUSD и присваивания значения counterparty для каждого DealSet\n",
    "\n",
    "    deals_data = data_Debt_work[['entity', 'Entity_group', 'counterparty','amount', 'amountUSD', 'instrumentOwner', 'dealSet']] # Выбор нужного разреза данных\n",
    "    deals_data_Bonds = deals_data[deals_data.dealSet.str.contains('Bond')] # Фильтрация разреза по значениям в DealSet, которые содержат слово Bond\n",
    "\n",
    "    Bonds_list = deals_data_Bonds.dealSet.unique()\n",
    "\n",
    "    for Bond in Bonds_list:\n",
    "        try:\n",
    "            Bond_data = deals_data_Bonds.query('dealSet ==@Bond') # Отбор данных одного Bond\n",
    "            assert len(Bond_data[Bond_data.instrumentOwner == 'EC_ISSUED_BONDS']) != 0\n",
    "\n",
    "            for column in Bond_data[['amount', 'amountUSD']]:\n",
    "                Traded_data_sum = Bond_data.query('instrumentOwner ==\"EC_TRADED_BONDS\"')[column].sum()\n",
    "                Issued_data = Bond_data.query('instrumentOwner ==\"EC_ISSUED_BONDS\"')[column]\n",
    "                # Внесение нового значения amount в issued bonds\n",
    "                Bond_data.loc[Bond_data['instrumentOwner'] ==\"EC_ISSUED_BONDS\", column] = Traded_data_sum + Issued_data \n",
    "            # Внесение нового значения counterparty в traded bonds\n",
    "            Issied_data_entity = Bond_data.query('instrumentOwner ==\"EC_ISSUED_BONDS\"').Entity.squeeze()\n",
    "            Bond_data.loc[Bond_data['instrumentOwner'] ==\"EC_TRADED_BONDS\", 'counterparty'] = Issied_data_entity\n",
    "            deals_data_Bonds.loc[deals_data_Bonds['dealSet'] == Bond] = Bond_data\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    deals_data.loc[deals_data.dealSet.str.contains('Bond')] = deals_data_Bonds\n",
    "    data_Debt_work[['entity', 'Entity_group', 'counterparty','amount', 'amountUSD', 'instrumentOwner', 'dealSet']] = deals_data\n",
    "    # Запись выполненного цикла в в основные данные\n",
    "\n",
    "    data_Debt_work = Period(data_Debt_work, day_for_count=Today, col_with_date='actionDate').reset_index(drop=True)\n",
    "\n",
    "    data_Debt_work.loc[data_Debt_work.counterparty.str.contains('(EC)'), 'counterparty'] = data_Debt_work.loc[data_Debt_work.counterparty.str.contains('(EC)'), 'counterparty'].str[:-5] \n",
    "    # Обрезка \" (EC)\" в каждой строке\n",
    "\n",
    "    data_Debt_work = data_Debt_work[~data_Debt_work.counterparty.isna()].reset_index(drop=True)\n",
    "    data_Debt_work['CompCode'] = merge_Mapping(data_Debt_work, col='counterparty').fillna('External')\n",
    "    data_Debt_work['Counterparty_Group'] = merge_SalesUnits(data_Debt_work, col='CompCode', merge_col='ocpSegment').fillna('External')\n",
    "    # Merge counterparty с Mapping и SalesUnits\n",
    "\n",
    "    data_Debt_work['Source'] = 'Quantum'\n",
    "\n",
    "    if i == 'SUEK':\n",
    "        data_Debt_work_SUEK = data_Debt_work\n",
    "    if i == 'EuroChem':\n",
    "        data_Debt_work_ECH = data_Debt_work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запись Debt в Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sheet_in_output_Debt = 'Debt'\n",
    "Output_Debt_SUEK = \"_\".join([str(date.today()), 'SUEK_quantum_Debt.xlsx'])\n",
    "Output_Debt_ECH = \"_\".join([str(date.today()), 'Ech_quantum_Debt.xlsx'])\n",
    "if excel_tofolder_on_Z == True:\n",
    "    Output_path = 'z:\\\\Anna_Klimova\\\\OCP\\\\Archive\\\\'\n",
    "    Output_Debt_SUEK = Output_path + Output_Debt_SUEK\n",
    "    Output_Debt_ECH = Output_path + Output_Debt_ECH\n",
    "\n",
    "data_Debt_export_for_print_SUEK = data_Debt_work_SUEK[['entity', 'Entity_group','counterparty',\\\n",
    "                                'Counterparty_Group','amount','eventCurrency','amountUSD','actionDate','Days',\\\n",
    "                                'Period','dealClass1','dealClass2','instrumentOwner','dealSet','facility','Source']]\\\n",
    "                                .rename(columns={'amount': 'amoutn outstanding',\\\n",
    "                                                    'eventCurrency': 'Currency',\\\n",
    "                                                    'amountUSD': 'amount USD eq',\\\n",
    "                                                    'actionDate': 'termEnd'})\n",
    "data_Debt_export_for_print_ECH = data_Debt_work_ECH[['entity', 'Entity_group','counterparty',\\\n",
    "                                'Counterparty_Group','amount','eventCurrency','amountUSD','actionDate','Days',\\\n",
    "                                'Period','dealClass1','dealClass2','instrumentOwner','dealSet','facility','Source']]\\\n",
    "                                .rename(columns={'amount': 'amoutn outstanding',\\\n",
    "                                                    'eventCurrency': 'Currency',\\\n",
    "                                                    'amountUSD': 'amount USD eq',\\\n",
    "                                                    'actionDate': 'termEnd'})\n",
    "\n",
    "if print_Debt == True:\n",
    "    data_Debt_export_for_print_SUEK.to_excel(Output_Debt_SUEK, sheet_name = Sheet_in_output_Debt, index = False)\n",
    "    data_Debt_export_for_print_ECH.to_excel(Output_Debt_ECH, sheet_name = Sheet_in_output_Debt, index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>Entity_group</th>\n",
       "      <th>counterparty</th>\n",
       "      <th>amount</th>\n",
       "      <th>amountUSD</th>\n",
       "      <th>instrumentOwner</th>\n",
       "      <th>dealSet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RUEMO</td>\n",
       "      <td>RUFERT</td>\n",
       "      <td>NSD RU</td>\n",
       "      <td>-2.500000e+10</td>\n",
       "      <td>-2.741625e+08</td>\n",
       "      <td>EC_ISSUED_BONDS</td>\n",
       "      <td>MCC RuBond 08 2020-04 R25b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entity Entity_group counterparty        amount     amountUSD  \\\n",
       "33  RUEMO       RUFERT       NSD RU -2.500000e+10 -2.741625e+08   \n",
       "\n",
       "    instrumentOwner                     dealSet  \n",
       "33  EC_ISSUED_BONDS  MCC RuBond 08 2020-04 R25b  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = data_Debt_work[['entity', 'Entity_group', 'counterparty','amount', 'amountUSD', 'instrumentOwner', 'dealSet']]\n",
    "check = check[check.instrumentOwner.str.contains('BONDS')].reset_index(drop=True)\n",
    "check[check.dealSet == check.dealSet.unique().tolist()[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counterparty</th>\n",
       "      <th>CompCode</th>\n",
       "      <th>Counterparty_Group</th>\n",
       "      <th>entity</th>\n",
       "      <th>Entity_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>Corrigo</td>\n",
       "      <td>External</td>\n",
       "      <td>External</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     counterparty  CompCode Counterparty_Group entity Entity_group\n",
       "1149      Corrigo  External           External    NaN          NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_map = data_Debt_work.loc[(data_Debt_work['cpartyType'] == 'Internal') & (data_Debt_work['CompCode'] == 'External'), ['counterparty', 'CompCode', 'Counterparty_Group']].drop_duplicates()\n",
    "manual_map\n",
    "\n",
    "manual_map2 = data_Debt_work.loc[data_Debt_work['Entity_group'] == 'External', ['entity', 'Entity_group']].drop_duplicates()\n",
    "manual_map2\n",
    "\n",
    "manual_map_print = pd.concat([manual_map, manual_map2], axis=1)\n",
    "manual_map_print\n",
    "# manual_map_print.to_excel('Manual_map.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работа с Forwards и Swaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:88: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((6, 80), (11, 84))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = f\"\"\"select * from \"RISKACCESS\".\"quantumForwards\" \"\"\"\n",
    "# data_Forwards_export = export_from_RISKCUSTOM(query)\n",
    "# data_Forwards_export[data_Forwards_export.positionDate > '2024-03-01'].positionDate.unique()\n",
    "\n",
    "query = f\"\"\"select * from \"RISKACCESS\".\"quantumForwards\" where \"positionDate\" = TO_DATE('{Today_1}', 'YYYY-MM-DD')\"\"\"\n",
    "data_Forwards_export = export_from_RISKCUSTOM(query)\n",
    "\n",
    "# query = f\"\"\"select * from \"RISKACCESS\".\"quantumSwaps\" \"\"\"\n",
    "# data_Swaps_export = export_from_RISKCUSTOM(query)\n",
    "# data_Swaps_export[data_Swaps_export.positionDate > '2024-03-01'].positionDate.unique\n",
    "query = f\"\"\"select * from \"RISKACCESS\".\"quantumSwaps\" where \"positionDate\" = TO_DATE('{Today_2}', 'DD/MM/YY')\"\"\"\n",
    "data_Swaps_export = export_from_RISKCUSTOM(query)\n",
    "\n",
    "data_Forwards_export.shape, data_Swaps_export.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_14832\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_14832\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_14832\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_14832\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_14832\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_14832\\388960480.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:88: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:158: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[f'Coef_to_{CCY_to}'] = df.date_CCY_from.replace(coef_dict).fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_Swaps_export is empty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:88: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\Working_attributes\\Defs.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES'\n",
      " 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES' 'NAMSALES']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', 'last_merge'] = merge_data.loc[merge_data[f'{id_colmn}_merge'] != 'External', f'{id_colmn}_merge']\n"
     ]
    }
   ],
   "source": [
    "data_work_list = [data_Forwards_export, data_Swaps_export]\n",
    "\n",
    "for data_Deriv_index in range(len(data_work_list)):\n",
    "    # Проверка вхождений dealNo в Debt и остановка процесса в случае отсутвия данных:\n",
    "    data_Deriv = data_work_list[data_Deriv_index]\n",
    "    dealNo_intersect_list = list(set(data_Deriv['dealNo']).intersection(set(data_Debt_export['dealNo'])))\n",
    "    data_work_Deriv = data_Deriv[~(data_Deriv.dealNo.isin(dealNo_intersect_list))]\n",
    "    if len(data_work_Deriv) == 0:\n",
    "        if data_Deriv_index == 0:\n",
    "            print('data_Forwards_export is empty')\n",
    "            data_print_Forwards = pd.DataFrame()\n",
    "            continue\n",
    "        else:\n",
    "            print('data_Swaps_export is empty')\n",
    "            data_print_Swaps = pd.DataFrame()\n",
    "            continue\n",
    "        \n",
    "    data_work_Deriv['holdingEntity'] = data_work_Deriv['holdingEntity'].replace({'XXTSU': 'SUEK'})\n",
    "\n",
    "    # Создание входящей пары внизу\n",
    "    Data_for_loop = data_work_Deriv[['entity','holdingEntity','counterparty','dealNo', 'payFaceValue', 'payFXCurrency', 'recFaceValue', 'recFXCurrency', 'maturityDate']]\n",
    "    for i in range(0, len(Data_for_loop)):\n",
    "        row_list = list(Data_for_loop.loc[i])\n",
    "        Data_for_loop.loc[len(Data_for_loop)] = row_list[:4] + row_list[6:8] + row_list[6:]\n",
    "        Data_for_loop.loc[i,'payFaceValue'] = Data_for_loop.loc[i,'payFaceValue'] * -1\n",
    "    Data_for_loop = Data_for_loop.sort_values('dealNo')\n",
    "    # цикл создания новых строк\n",
    "    Data_for_loop = Period(Data_for_loop, day_for_count=Today_1, col_with_date='maturityDate')\n",
    "    # Создание Days и Period\n",
    "    Data_for_loop = add_in_currency_column(Data_for_loop, CCY_to='USD', col_with_CCY='payFXCurrency', date_is_column=False, col_with_VAL='payFaceValue', DATE=Today_1)\n",
    "    # создание payFaceValue_in_USD\n",
    "    new_columns = ['Company', 'Settlement', 'Notional_Amount_(USD)', 'Unnamed', 'source']\n",
    "    Data_for_loop = Data_for_loop.reindex(columns=(Data_for_loop.columns.tolist() + new_columns))\n",
    "    Data_for_loop['source'] = 'Quantum'\n",
    "    # Создание пустых столбцов и столбца ресурса\n",
    "\n",
    "    if data_Deriv_index == 0:\n",
    "        data_print_Forwards = Data_for_loop\n",
    "    else:\n",
    "        data_print_Swaps = Data_for_loop\n",
    "\n",
    "data_print_Deriv = pd.concat([data_print_Forwards, data_print_Swaps], axis=0)\n",
    "# Объединение таблиц вниз\n",
    "\n",
    "data_print_Deriv_columns = {x:y for x,y in zip(data_print_Deriv.columns.tolist(), [[] for x in data_print_Deriv.columns.tolist()])}\n",
    "data_print_Deriv_columns['Entity_group']=[]\n",
    "data_print_Deriv_SUEK = pd.DataFrame(data_print_Deriv_columns)\n",
    "data_print_Deriv_Ech = pd.DataFrame(data_print_Deriv_columns)\n",
    "for i in ['SUEK', 'EuroChem']:\n",
    "    data_print_Deriv_group = data_print_Deriv[data_print_Deriv.holdingEntity == i].reset_index(drop=True)\n",
    "    if len(data_print_Deriv_group) == 0:\n",
    "        continue   \n",
    "    if i == 'SUEK':\n",
    "        data_print_Deriv_group = data_print_Deriv_group.rename(columns={'entity': 'pre_entity'})\n",
    "        data_print_Deriv_group['entity'] = merge_Mapping(Data_for_loop, col='pre_entity')\n",
    "        \n",
    "    data_print_Deriv_group['Entity_group'] = merge_SalesUnits(data_print_Deriv_group, col='entity', merge_col='ocpSegment').fillna('External')\n",
    "    data_print_Deriv_group = data_print_Deriv_group[['entity','Entity_group','holdingEntity','Company',\\\n",
    "        'counterparty','dealNo','payFXCurrency','payFaceValue',\\\n",
    "        'payFaceValue_in_USD','Settlement','Notional_Amount_(USD)',\\\n",
    "        'Unnamed','maturityDate','Days','Period','source']]\n",
    "    if i == 'SUEK':\n",
    "        data_print_Deriv_SUEK = data_print_Deriv_group\n",
    "    if i == 'EuroChem':\n",
    "        data_print_Deriv_Ech = data_print_Deriv_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запись Deriv в файл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sheet_in_output_Deriv = 'Deriv'\n",
    "Output_Deriv_SUEK = \"_\".join([str(date.today()), 'SUEK_quantum_Deriv.xlsx'])\n",
    "Output_Deriv_Ech = \"_\".join([str(date.today()), 'Ech_quantum_Deriv.xlsx'])\n",
    "if excel_tofolder_on_Z == True:\n",
    "    Output_path = 'z:\\\\Anna_Klimova\\\\OCP\\\\Archive\\\\'\n",
    "    Output_Deriv_SUEK = Output_path + Output_Deriv_SUEK\n",
    "    Output_Deriv_Ech = Output_path + Output_Deriv_Ech\n",
    "\n",
    "if print_Deriv == True:\n",
    "    if len(data_print_Deriv_SUEK) != 0:\n",
    "        data_print_Deriv_SUEK.to_excel(Output_Deriv_SUEK, sheet_name=Sheet_in_output_Deriv, index=False)\n",
    "    if len(data_print_Deriv_Ech) != 0:\n",
    "        data_print_Deriv_Ech.to_excel(Output_Deriv_Ech, sheet_name=Sheet_in_output_Deriv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 2==1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
